<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[油脂青年]]></title>
  <link href="https://penghuicai.github.io/atom.xml" rel="self"/>
  <link href="https://penghuicai.github.io/"/>
  <updated>2023-03-09T11:05:47+08:00</updated>
  <id>https://penghuicai.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[`尚硅谷_ShardingSphere5`                                                                                       让天下没有难学的技术]]></title>
    <link href="https://penghuicai.github.io/16774110810352.html"/>
    <updated>2023-02-26T19:31:21+08:00</updated>
    <id>https://penghuicai.github.io/16774110810352.html</id>
    <content type="html"><![CDATA[
<hr/>

<h1 id="toc_0">第01章 高性能架构模式</h1>

<p>互联网业务兴起之后，海量用户加上海量数据的特点，单个数据库服务器已经难以满足业务需要，必须考虑数据库集群的方式来提升性能。高性能数据库集群的<code>第一种方式是“读写分离”</code>，<code>第二种方式是“数据库分片”</code>。</p>

<h2 id="toc_1">1、读写分离架构</h2>

<p><strong>读写分离原理：</strong>读写分离的基本原理是将数据库读写操作分散到不同的节点上，下面是其基本架构图：</p>

<p><img src="assets/362d22168bf344687ec0c206aa115807.jpg" alt="img"/></p>

<p><strong>读写分离的基本实现：</strong></p>

<ul>
<li> <code>主库负责处理事务性的增删改操作，从库负责处理查询操作</code>，能够有效的避免由数据更新导致的行锁，使得整个系统的查询性能得到极大的改善。</li>
<li> 读写分离是<code>根据 SQL 语义的分析</code>，<code>将读操作和写操作分别路由至主库与从库</code>。</li>
<li>通过<code>一主多从</code>的配置方式，可以将查询请求均匀的分散到多个数据副本，能够进一步的提升系统的处理能力。 </li>
<li>使用<code>多主多从</code>的方式，不但能够提升系统的吞吐量，还能够提升系统的可用性，可以达到在任何一个数据库宕机，甚至磁盘物理损坏的情况下仍然不影响系统的正常运行。</li>
</ul>

<p><strong>下图展示了根据业务需要，将用户表的写操作和读操路由到不同的数据库的方案：</strong></p>

<p><img src="assets/image-20220804223138651.png" alt="image-20220804223138651"/></p>

<p><strong>CAP 理论：</strong></p>

<p>CAP 定理（CAP theorem）又被称作布鲁尔定理（Brewer&#39;s theorem），是加州大学伯克利分校的计算机科学家埃里克·布鲁尔（Eric Brewer）在 2000 年的 ACM PODC 上提出的一个猜想。<code>对于设计分布式系统的架构师来说，CAP 是必须掌握的理论。</code></p>

<p>在一个<code>分布式系统中</code>，当涉及读写操作时，只能保证一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance）三者中的两个，另外一个必须被牺牲。</p>

<ul>
<li>C 一致性（Consistency）：对某个指定的客户端来说，读操作保证能够返回最新的写操作结果</li>
<li>A 可用性（Availability）：非故障的节点在合理的时间内返回合理的响应<code>（不是错误和超时的响应）</code></li>
<li>P 分区容忍性（Partition Tolerance）：当出现网络分区后<code>（可能是丢包，也可能是连接中断，还可能是拥塞）</code>，系统能够继续“履行职责”</li>
</ul>

<p><strong>CAP特点：</strong></p>

<ul>
<li><p>在实际设计过程中，每个系统不可能只处理一种数据，而是包含多种类型的数据，<code>有的数据必须选择 CP，有的数据必须选择 AP，分布式系统理论上不可能选择 CA 架构。</code></p>
<ul>
<li>CP：如下图所示，<code>为了保证一致性</code>，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。<code>这时客户端 C 访问 N2 时，N2 需要返回 Error，提示客户端 C“系统现在发生了错误”，</code>这种处理方式<code>违背了可用性</code>（Availability）的要求，因此 CAP 三者只能满足 CP。</li>
</ul>
<p><img src="assets/6e7d7bd54d7a4eb67918080863d354d7.png" alt="img"/></p>
<ul>
<li>AP：如下图所示，<code>为了保证可用性</code>，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。<code>这时客户端 C 访问 N2 时，N2 将当前自己拥有的数据 x 返回给客户端 C 了</code>，而实际上当前最新的数据已经是 y 了，这就<code>不满足一致性</code>（Consistency）的要求了，因此 CAP 三者只能满足 AP。注意：这里 N2 节点返回 x，虽然不是一个“正确”的结果，但是一个“合理”的结果，因为 x 是旧的数据，并不是一个错乱的值，只是不是最新的数据而已。</li>
</ul></li>
</ul>

<p><img src="assets/2ccafe41de9bd7f8dec4658f004310d6.png" alt="img"/></p>

<ul>
<li><p>CAP 理论中的 <code>C 在实践中是不可能完美实现的</code>，在数据复制的过程中，节点N1 和节点 N2 的数据并不一致（强一致性）。即使无法做到<code>强一致性</code>，但应用可以采用适合的方式达到<code>最终一致性</code>。具有如下特点：</p>
<ul>
<li>基本可用（Basically Available）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。</li>
<li>软状态（Soft State）：允许系统存在中间状态，而该中间状态不会影响系统整体可用性。这里的中间状态就是 CAP 理论中的数据不一致。</li>
<li><code>最终一致性（Eventual Consistency）：系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。</code></li>
</ul></li>
</ul>

<h2 id="toc_2">2、数据库分片架构</h2>

<p><strong>读写分离的问题：</strong></p>

<p>读写分离分散了数据库读写操作的压力，但没有分散存储压力，为了满足业务数据存储的需求，就需要<code>将存储分散到多台数据库服务器上</code>。</p>

<p><strong>数据分片：</strong></p>

<p>将存放在单一数据库中的数据分散地存放至多个数据库或表中，以达到提升性能瓶颈以及可用性的效果。 数据分片的有效手段是对关系型数据库进行<code>分库和分表</code>。数据分片的拆分方式又分为<code>垂直分片和水平分片</code>。</p>

<h3 id="toc_3">2.1、垂直分片</h3>

<p><strong>垂直分库：</strong></p>

<p><code>按照业务拆分的方式称为垂直分片，又称为纵向拆分</code>，它的核心理念是专库专用。 在拆分之前，一个数据库由多个数据表构成，每个表对应着不同的业务。而拆分之后，则是按照业务将表进行归类，分布到不同的数据库中，从而将压力分散至不同的数据库。 </p>

<p><img src="assets/71f41d46cc5c0405f4d4dc944b4350c9.jpg" alt="img"/></p>

<p>下图展示了根据业务需要，将用户表和订单表垂直分片到不同的数据库的方案：</p>

<p><img src="assets/image-20220804221855449.png" alt="image-20220804221855449"/></p>

<p>垂直拆分可以缓解数据量和访问量带来的问题，但无法根治。<code>如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理。</code></p>

<p><strong>垂直分表：</strong></p>

<p><code>垂直分表适合将表中某些不常用的列，或者是占了大量空间的列拆分出去。</code></p>

<p>假设我们是一个婚恋网站，用户在筛选其他用户的时候，主要是用 age 和 sex 两个字段进行查询，而 nickname 和 description 两个字段主要用于展示，一般不会在业务查询中用到。description 本身又比较长，因此我们可以将这两个字段独立到另外一张表中，这样在查询 age 和 sex 时，就能带来一定的性能提升。</p>

<p>垂直分表引入的复杂性主要体现在表操作的数量要增加。例如，原来只要一次查询就可以获取 name、age、sex、nickname、description，现在需要两次查询，一次查询获取 name、age、sex，另外一次查询获取 nickname、description。</p>

<p><img src="assets/136bc2f01919edcb8271df6f7e71af40.jpg" alt="img"/></p>

<p><code>水平分表适合表行数特别大的表，水平分表属于水平分片</code>。</p>

<h3 id="toc_4">2.2、水平分片</h3>

<p><code>水平分片又称为横向拆分。</code> 相对于垂直分片，它不再将数据根据业务逻辑分类，而是通过某个字段（或某几个字段），根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分。 例如：根据主键分片，偶数主键的记录放入 0 库（或表），奇数主键的记录放入 1 库（或表），如下图所示。</p>

<p><img src="assets/image-20220804222212087.png" alt="image-20220804222212087"/></p>

<p><code>单表进行切分后，是否将多个表分散在不同的数据库服务器中，可以根据实际的切分效果来确定。</code></p>

<ul>
<li><p><strong>水平分表：</strong>单表切分为多表后，新的表即使在同一个数据库服务器中，也可能带来可观的性能提升，如果性能能够满足业务要求，可以不拆分到多台数据库服务器，毕竟业务分库也会引入很多复杂性；</p></li>
<li><p><strong>水平分库：</strong>如果单表拆分为多表后，单台服务器依然无法满足性能要求，那就需要将多个表分散在不同的数据库服务器中。</p></li>
</ul>

<blockquote>
<p><strong>阿里巴巴Java开发手册：</strong></p>

<p>【推荐】单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。</p>

<p>说明：如果预计三年后的数据量根本达不到这个级别，<code>请不要在创建表时就分库分表</code>。</p>
</blockquote>

<h2 id="toc_5">3、读写分离和数据分片架构</h2>

<p>下图展现了将数据分片与读写分离一同使用时，应用程序与数据库集群之间的复杂拓扑关系。</p>

<p><img src="assets/image-20220804223321167.png" alt="image-20220804223321167"/></p>

<h2 id="toc_6">4、实现方式</h2>

<p>读写分离和数据分片具体的实现方式一般有两种：  <code>程序代码封装</code>和<code>中间件封装</code>。</p>

<h3 id="toc_7">4.1、程序代码封装</h3>

<p>程序代码封装指在代码中抽象一个<code>数据访问层（或中间层封装）</code>，实现读写操作分离和数据库服务器连接的管理。</p>

<p><strong>其基本架构是：</strong>以读写分离为例</p>

<p><img src="assets/f8d538f9201e3ebee37dfdcd1922e9df.jpg" alt="img"/></p>

<h3 id="toc_8">4.2、中间件封装</h3>

<p>中间件封装指的是<code>独立一套系统出来</code>，实现读写操作分离和数据库服务器连接的管理。对于业务服务器来说，访问中间件和访问数据库没有区别，在业务服务器看来，中间件就是一个数据库服务器。</p>

<p><strong>基本架构是：</strong>以读写分离为例</p>

<p><img src="assets/2a2dba7f07581fd055d9cd5a3aa8388e.jpg" alt="img"/></p>

<h3 id="toc_9">4.3、常用解决方案</h3>

<p>Apache ShardingSphere（程序级别和中间件级别）</p>

<p>MyCat（数据库中间件） </p>

<h1 id="toc_10">第02章 ShardingSphere</h1>

<h2 id="toc_11">1、简介</h2>

<p>官网：<a href="https://shardingsphere.apache.org/index_zh.html">https://shardingsphere.apache.org/index_zh.html</a></p>

<p>文档：<a href="https://shardingsphere.apache.org/document/5.1.1/cn/overview/">https://shardingsphere.apache.org/document/5.1.1/cn/overview/</a></p>

<p>Apache ShardingSphere 由 JDBC、Proxy 和 Sidecar（规划中）这 3 款既能够独立部署，又支持混合部署配合使用的产品组成。 </p>

<h2 id="toc_12">2、ShardingSphere-JDBC</h2>

<p><strong>程序代码封装</strong></p>

<p>定位为轻量级 Java 框架，<code>在 Java 的 JDBC 层提供的额外服务</code>。 它使用客户端直连数据库，<code>以 jar 包形式提供服务</code>，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。</p>

<p><img src="assets/image-20220804195402870.png" alt="image-20220804195402870"/></p>

<h2 id="toc_13">3、ShardingSphere-Proxy</h2>

<p><strong>中间件封装</strong></p>

<p>定位为透明化的<code>数据库代理端</code>，提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持。 目前提供 MySQL 和 PostgreSQL版本，它可以使用任何兼容 MySQL/PostgreSQL 协议的访问客户端（如：MySQL Command Client, MySQL Workbench, Navicat 等）操作数据，对 DBA 更加友好。</p>

<p><img src="assets/image-20220804195432673.png" alt="image-20220804195432673"/></p>

<h1 id="toc_14">第03章 MySQL主从同步</h1>

<h2 id="toc_15">1、MySQL主从同步原理</h2>

<p><img src="assets/image-20220714133617856.png" alt="img"/></p>

<p><strong>基本原理：</strong></p>

<p>slave会从master读取binlog来进行数据同步</p>

<p><strong>具体步骤：</strong></p>

<ul>
<li><code>step1：</code>master将数据改变记录到<code>二进制日志（binary log）</code>中。</li>
<li><code>step2：</code> 当slave上执行 <code>start slave</code> 命令之后，slave会创建一个 <code>IO 线程</code>用来连接master，请求master中的binlog。</li>
<li><code>step3：</code>当slave连接master时，master会创建一个 <code>log dump 线程</code>，用于发送 binlog 的内容。在读取 binlog 的内容的操作中，会对主节点上的 binlog 加锁，当读取完成并发送给从服务器后解锁。</li>
<li><code>step4：</code>IO 线程接收主节点 binlog dump 进程发来的更新之后，保存到 <code>中继日志（relay log）</code> 中。</li>
<li><code>step5：</code>slave的<code>SQL线程</code>，读取relay log日志，并解析成具体操作，从而实现主从操作一致，最终数据一致。</li>
</ul>

<h2 id="toc_16">2、一主多从配置</h2>

<p>服务器规划：使用<code>docker</code>方式创建，<code>主从服务器IP一致，端口号不一致</code></p>

<p><img src="assets/image-20220807183231101.png" alt="image-20220807183231101"/></p>

<ul>
<li>主服务器：容器名<code>atguigu-mysql-master</code>，端口<code>3306</code></li>
<li>从服务器：容器名<code>atguigu-mysql-slave1</code>，端口<code>3307</code></li>
<li>从服务器：容器名<code>atguigu-mysql-slave2</code>，端口<code>3308</code></li>
</ul>

<p><strong>注意：</strong>如果此时防火墙是开启的，<code>则先关闭防火墙，并重启docker</code>，否则后续安装的MySQL无法启动</p>

<pre class="line-numbers"><code class="language-shell">#关闭docker
systemctl stop docker
#关闭防火墙
systemctl stop firewalld
#启动docker
systemctl start docker
</code></pre>

<h3 id="toc_17">2.1、准备主服务器</h3>

<ul>
<li><strong>step1：在docker中创建并启动MySQL主服务器：</strong><code>端口3306</code></li>
</ul>

<pre class="line-numbers"><code class="language-shell">docker run -d \
-p 3306:3306 \
-v /atguigu/mysql/master/conf:/etc/mysql/conf.d \
-v /atguigu/mysql/master/data:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=123456 \
--name atguigu-mysql-master \
mysql:8.0.29
</code></pre>

<ul>
<li><strong>step2：创建MySQL主服务器配置文件：</strong> </li>
</ul>

<p>默认情况下MySQL的binlog日志是自动开启的，可以通过如下配置定义一些可选配置</p>

<pre class="line-numbers"><code class="language-shell">vim /atguigu/mysql/master/conf/my.cnf
</code></pre>

<p>配置如下内容</p>

<pre class="line-numbers"><code class="language-properties">[mysqld]
# 服务器唯一id，默认值1
server-id=1
# 设置日志格式，默认值ROW
binlog_format=STATEMENT
# 二进制日志名，默认binlog
# log-bin=binlog
# 设置需要复制的数据库，默认复制全部数据库
#binlog-do-db=mytestdb
# 设置不需要复制的数据库
#binlog-ignore-db=mysql
#binlog-ignore-db=infomation_schema
</code></pre>

<p>重启MySQL容器</p>

<pre class="line-numbers"><code class="language-shell">docker restart atguigu-mysql-master
</code></pre>

<p><code>binlog格式说明：</code></p>

<ul>
<li>binlog_format=STATEMENT：日志记录的是主机数据库的<code>写指令</code>，性能高，但是now()之类的函数以及获取系统参数的操作会出现主从数据不同步的问题。</li>
<li>binlog_format=ROW（默认）：日志记录的是主机数据库的<code>写后的数据</code>，批量操作时性能较差，解决now()或者  user()或者  @@hostname 等操作在主从机器上不一致的问题。</li>
<li>binlog_format=MIXED：是以上两种level的混合使用，有函数用ROW，没函数用STATEMENT，但是无法识别系统变量</li>
</ul>

<p><code>binlog-ignore-db和binlog-do-db的优先级问题：</code></p>

<p><img src="assets/0.08703112216569037.png" alt="img"/></p>

<ul>
<li><strong>step3：使用命令行登录MySQL主服务器：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-shell">#进入容器：env LANG=C.UTF-8 避免容器中显示中文乱码
docker exec -it atguigu-mysql-master env LANG=C.UTF-8 /bin/bash
#进入容器内的mysql命令行
mysql -uroot -p
#修改默认密码校验方式
ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;
</code></pre>

<ul>
<li><strong>step4：主机中创建slave用户：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-sql">-- 创建slave用户
CREATE USER &#39;atguigu_slave&#39;@&#39;%&#39;;
-- 设置密码
ALTER USER &#39;atguigu_slave&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;
-- 授予复制权限
GRANT REPLICATION SLAVE ON *.* TO &#39;atguigu_slave&#39;@&#39;%&#39;;
-- 刷新权限
FLUSH PRIVILEGES;
</code></pre>

<ul>
<li><strong>step5：主机中查询master状态：</strong></li>
</ul>

<p>执行完此步骤后<code>不要再操作主服务器MYSQL</code>，防止主服务器状态值变化</p>

<pre class="line-numbers"><code class="language-sql">SHOW MASTER STATUS;
</code></pre>

<p>记下<code>File</code>和<code>Position</code>的值。执行完此步骤后不要再操作主服务器MYSQL，防止主服务器状态值变化。</p>

<p><img src="assets/image-20220804191852164.png" alt="image-20220804191852164"/></p>

<h3 id="toc_18">2.2、准备从服务器</h3>

<p>可以配置多台从机slave1、slave2...，这里以配置slave1为例</p>

<ul>
<li><strong>step1：在docker中创建并启动MySQL从服务器：</strong><code>端口3307</code></li>
</ul>

<pre class="line-numbers"><code class="language-shell">docker run -d \
-p 3307:3306 \
-v /atguigu/mysql/slave1/conf:/etc/mysql/conf.d \
-v /atguigu/mysql/slave1/data:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=123456 \
--name atguigu-mysql-slave1 \
mysql:8.0.29
</code></pre>

<ul>
<li><strong>step2：创建MySQL从服务器配置文件：</strong> </li>
</ul>

<pre class="line-numbers"><code class="language-shell">vim /atguigu/mysql/slave1/conf/my.cnf
</code></pre>

<p>配置如下内容：</p>

<pre class="line-numbers"><code class="language-properties">[mysqld]
# 服务器唯一id，每台服务器的id必须不同，如果配置其他从机，注意修改id
server-id=2
# 中继日志名，默认xxxxxxxxxxxx-relay-bin
#relay-log=relay-bin
</code></pre>

<p>重启MySQL容器</p>

<pre class="line-numbers"><code class="language-shell">docker restart atguigu-mysql-slave1
</code></pre>

<ul>
<li><strong>step3：使用命令行登录MySQL从服务器：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-shell">#进入容器：
docker exec -it atguigu-mysql-slave1 env LANG=C.UTF-8 /bin/bash
#进入容器内的mysql命令行
mysql -uroot -p
#修改默认密码校验方式
ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;
</code></pre>

<ul>
<li><strong>step4：在从机上配置主从关系：</strong></li>
</ul>

<p>在<strong>从机</strong>上执行以下SQL操作</p>

<pre class="line-numbers"><code class="language-sql">CHANGE MASTER TO MASTER_HOST=&#39;192.168.100.201&#39;, 
MASTER_USER=&#39;atguigu_slave&#39;,MASTER_PASSWORD=&#39;123456&#39;, MASTER_PORT=3306,
MASTER_LOG_FILE=&#39;binlog.000003&#39;,MASTER_LOG_POS=1357; 
</code></pre>

<h3 id="toc_19">2.3、启动主从同步</h3>

<p>启动从机的复制功能，执行SQL：</p>

<pre class="line-numbers"><code class="language-sql">START SLAVE;
-- 查看状态（不需要分号）
SHOW SLAVE STATUS\G
</code></pre>

<p><strong>两个关键进程：</strong>下面两个参数都是Yes，则说明主从配置成功！</p>

<p><img src="assets/image-20220715000533951.png" alt="img"/></p>

<h3 id="toc_20">2.4、实现主从同步</h3>

<p>在主机中执行以下SQL，在从机中查看数据库、表和数据是否已经被同步</p>

<pre class="line-numbers"><code class="language-sql">CREATE DATABASE db_user;
USE db_user;
CREATE TABLE t_user (
 id BIGINT AUTO_INCREMENT,
 uname VARCHAR(30),
 PRIMARY KEY (id)
);
INSERT INTO t_user(uname) VALUES(&#39;zhang3&#39;);
INSERT INTO t_user(uname) VALUES(@@hostname);
</code></pre>

<h3 id="toc_21">2.5、停止和重置</h3>

<p>需要的时候，可以使用如下SQL语句</p>

<pre class="line-numbers"><code class="language-sql">-- 在从机上执行。功能说明：停止I/O 线程和SQL线程的操作。
stop slave; 

-- 在从机上执行。功能说明：用于删除SLAVE数据库的relaylog日志文件，并重新启用新的relaylog文件。
reset slave;

-- 在主机上执行。功能说明：删除所有的binglog日志文件，并将日志索引文件清空，重新开始所有新的日志文件。
-- 用于第一次进行搭建主从库时，进行主库binlog初始化工作；
reset master;
</code></pre>

<h3 id="toc_22"><strong>2.6、常见问题</strong></h3>

<h4 id="toc_23">问题1</h4>

<p>启动主从同步后，常见错误是<code>Slave_IO_Running： No 或者 Connecting</code> 的情况，此时查看下方的 <code>Last_IO_ERROR</code>错误日志，根据日志中显示的错误信息在网上搜索解决方案即可</p>

<p><img src="assets/image-20220714235426120.png" alt="img"/></p>

<p><strong>典型的错误例如：</strong><code>Last_IO_Error: Got fatal error 1236 from master when reading data from binary log: &#39;Client requested master to start replication from position &gt; file size&#39;</code></p>

<p><strong>解决方案：</strong></p>

<pre class="line-numbers"><code class="language-sql">-- 在从机停止slave
SLAVE STOP;

-- 在主机查看mater状态
SHOW MASTER STATUS;
-- 在主机刷新日志
FLUSH LOGS;
-- 再次在主机查看mater状态（会发现File和Position发生了变化）
SHOW MASTER STATUS;
-- 修改从机连接主机的SQL，并重新连接即可
</code></pre>

<h4 id="toc_24">问题2</h4>

<p>启动docker容器后提示 <code>WARNING: IPv4 forwarding is disabled. Networking will not work.</code></p>

<p><img src="assets/image-20220715004850504.png" alt="img"/></p>

<p>此错误，虽然不影响主从同步的搭建，但是如果想从远程客户端通过以下方式连接docker中的MySQL则没法连接</p>

<pre class="line-numbers"><code class="language-shell">C:\Users\administrator&gt;mysql -h 192.168.100.201 -P 3306 -u root -p
</code></pre>

<p><strong>解决方案：</strong></p>

<pre class="line-numbers"><code class="language-shell">#修改配置文件：
vim /usr/lib/sysctl.d/00-system.conf
#追加
net.ipv4.ip_forward=1
#接着重启网络
systemctl restart network
</code></pre>

<h1 id="toc_25">第04章 ShardingSphere-JDBC读写分离</h1>

<h2 id="toc_26">1、创建SpringBoot程序</h2>

<h3 id="toc_27">1.1、创建项目</h3>

<p>项目类型：Spring Initializr</p>

<p>SpringBoot脚手架：<a href="http://start.aliyun.com">http://start.aliyun.com</a></p>

<p>项目名：sharding-jdbc-demo</p>

<p>SpringBoot版本：2.3.7.RELEASE</p>

<h3 id="toc_28">1.2、添加依赖</h3>

<pre class="line-numbers"><code class="language-markup">&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;
        &lt;artifactId&gt;shardingsphere-jdbc-core-spring-boot-starter&lt;/artifactId&gt;
        &lt;version&gt;5.1.1&lt;/version&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;mysql&lt;/groupId&gt;
        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
        &lt;scope&gt;runtime&lt;/scope&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
        &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
        &lt;version&gt;3.3.1&lt;/version&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
        &lt;artifactId&gt;lombok&lt;/artifactId&gt;
        &lt;optional&gt;true&lt;/optional&gt;
    &lt;/dependency&gt;
    
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
        &lt;scope&gt;test&lt;/scope&gt;
        &lt;exclusions&gt;
            &lt;exclusion&gt;
                &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt;
                &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt;
            &lt;/exclusion&gt;
        &lt;/exclusions&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>

<h3 id="toc_29">1.3、创建实体类</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo.entity;

@TableName(&quot;t_user&quot;)
@Data
public class User {
    @TableId(type = IdType.AUTO)
    private Long id;
    private String uname;
}
</code></pre>

<h3 id="toc_30">1.4、创建Mapper</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo.mapper;

@Mapper
public interface UserMapper extends BaseMapper&lt;User&gt; {
}
</code></pre>

<h3 id="toc_31">1.5、配置读写分离</h3>

<p>application.properties：</p>

<pre class="line-numbers"><code class="language-properties"># 应用名称
spring.application.name=sharging-jdbc-demo
# 开发环境设置
spring.profiles.active=dev
# 内存模式
spring.shardingsphere.mode.type=Memory

# 配置真实数据源
spring.shardingsphere.datasource.names=master,slave1,slave2

# 配置第 1 个数据源
spring.shardingsphere.datasource.master.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.master.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.master.jdbc-url=jdbc:mysql://192.168.100.201:3306/db_user
spring.shardingsphere.datasource.master.username=root
spring.shardingsphere.datasource.master.password=123456

# 配置第 2 个数据源
spring.shardingsphere.datasource.slave1.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.slave1.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.slave1.jdbc-url=jdbc:mysql://192.168.100.201:3307/db_user
spring.shardingsphere.datasource.slave1.username=root
spring.shardingsphere.datasource.slave1.password=123456

# 配置第 3 个数据源
spring.shardingsphere.datasource.slave2.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.slave2.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.slave2.jdbc-url=jdbc:mysql://192.168.100.201:3308/db_user
spring.shardingsphere.datasource.slave2.username=root
spring.shardingsphere.datasource.slave2.password=123456

# 读写分离类型，如: Static，Dynamic
spring.shardingsphere.rules.readwrite-splitting.data-sources.myds.type=Static
# 写数据源名称
spring.shardingsphere.rules.readwrite-splitting.data-sources.myds.props.write-data-source-name=master
# 读数据源名称，多个从数据源用逗号分隔
spring.shardingsphere.rules.readwrite-splitting.data-sources.myds.props.read-data-source-names=slave1,slave2

# 负载均衡算法名称
spring.shardingsphere.rules.readwrite-splitting.data-sources.myds.load-balancer-name=alg_round

# 负载均衡算法配置
# 负载均衡算法类型
spring.shardingsphere.rules.readwrite-splitting.load-balancers.alg_round.type=ROUND_ROBIN
spring.shardingsphere.rules.readwrite-splitting.load-balancers.alg_random.type=RANDOM
spring.shardingsphere.rules.readwrite-splitting.load-balancers.alg_weight.type=WEIGHT
spring.shardingsphere.rules.readwrite-splitting.load-balancers.alg_weight.props.slave1=1
spring.shardingsphere.rules.readwrite-splitting.load-balancers.alg_weight.props.slave2=2

# 打印SQl
spring.shardingsphere.props.sql-show=true
</code></pre>

<h2 id="toc_32">2、测试</h2>

<h3 id="toc_33">2.1、读写分离测试</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo;

@SpringBootTest
class ReadwriteTest {

    @Autowired
    private UserMapper userMapper;

    /**
     * 写入数据的测试
     */
    @Test
    public void testInsert(){

        User user = new User();
        user.setUname(&quot;张三丰&quot;);
        userMapper.insert(user);
    }

}
</code></pre>

<h3 id="toc_34">2.2、事务测试</h3>

<p>为了保证主从库间的事务一致性，避免跨服务的分布式事务，ShardingSphere-JDBC的<code>主从模型中，事务中的数据读写均用主库</code>。</p>

<ul>
<li>不添加@Transactional：insert对主库操作，select对从库操作</li>
<li>添加@Transactional：则insert和select均对主库操作</li>
<li><strong>注意：</strong>在JUnit环境下的@Transactional注解，默认情况下就会对事务进行回滚（即使在没加注解@Rollback，也会对事务回滚）</li>
</ul>

<pre class="line-numbers"><code class="language-java">/**
     * 事务测试
     */
@Transactional//开启事务
@Test
public void testTrans(){

    User user = new User();
    user.setUname(&quot;铁锤&quot;);
    userMapper.insert(user);

    List&lt;User&gt; users = userMapper.selectList(null);
}
</code></pre>

<h3 id="toc_35">2.3、负载均衡测试</h3>

<pre class="line-numbers"><code class="language-java">
/**
     * 读数据测试
     */
@Test
public void testSelectAll(){
    List&lt;User&gt; users = userMapper.selectList(null);
    List&lt;User&gt; users = userMapper.selectList(null);//执行第二次测试负载均衡
    users.forEach(System.out::println);
}

</code></pre>

<p>也可以在web请求中测试负载均衡</p>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo.controller;

@RestController
@RequestMapping(&quot;/userController&quot;)
public class UserController {

    @Autowired
    private UserMapper userMapper;

    /**
     * 测试负载均衡策略
     */
    @GetMapping(&quot;selectAll&quot;)
    public void selectAll(){
        List&lt;User&gt; users = userMapper.selectList(null);
        users.forEach(System.out::println);
    }
}
</code></pre>

<h1 id="toc_36">第05章 ShardingSphere-JDBC垂直分片</h1>

<h2 id="toc_37">1、准备服务器</h2>

<p>服务器规划：使用<code>docker</code>方式创建如下容器</p>

<p><img src="assets/image-20220807232456342.png" alt="image-20220807232456342"/></p>

<ul>
<li><p>服务器：容器名<code>server-user</code>，端口<code>3301</code></p></li>
<li><p>服务器：容器名<code>server-order</code>，端口<code>3302</code></p></li>
</ul>

<h3 id="toc_38">1.1、创建server-user容器</h3>

<ul>
<li><strong>step1：创建容器：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-shell">docker run -d \
-p 3301:3306 \
-v /atguigu/server/user/conf:/etc/mysql/conf.d \
-v /atguigu/server/user/data:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=123456 \
--name server-user \
mysql:8.0.29
</code></pre>

<ul>
<li><strong>step2：登录MySQL服务器：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-shell">#进入容器：
docker exec -it server-user env LANG=C.UTF-8 /bin/bash
#进入容器内的mysql命令行
mysql -uroot -p
#修改默认密码插件
ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;
</code></pre>

<ul>
<li><strong>step3：创建数据库：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-sql">CREATE DATABASE db_user;
USE db_user;
CREATE TABLE t_user (
 id BIGINT AUTO_INCREMENT,
 uname VARCHAR(30),
 PRIMARY KEY (id)
);
</code></pre>

<h3 id="toc_39">1.2、创建server-order容器</h3>

<ul>
<li><strong>step1：创建容器：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-shell">docker run -d \
-p 3302:3306 \
-v /atguigu/server/order/conf:/etc/mysql/conf.d \
-v /atguigu/server/order/data:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=123456 \
--name server-order \
mysql:8.0.29
</code></pre>

<ul>
<li><strong>step2：登录MySQL服务器：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-shell">#进入容器：
docker exec -it server-order env LANG=C.UTF-8 /bin/bash
#进入容器内的mysql命令行
mysql -uroot -p
#修改默认密码插件
ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;
</code></pre>

<ul>
<li><strong>step3：创建数据库：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-sql">CREATE DATABASE db_order;
USE db_order;
CREATE TABLE t_order (
  id BIGINT AUTO_INCREMENT,
  order_no VARCHAR(30),
  user_id BIGINT,
  amount DECIMAL(10,2),
  PRIMARY KEY(id) 
);
</code></pre>

<h2 id="toc_40">2、程序实现</h2>

<h3 id="toc_41">2.1、创建实体类</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo.entity;

@TableName(&quot;t_order&quot;)
@Data
public class Order {
    @TableId(type = IdType.AUTO)
    private Long id;
    private String orderNo;
    private Long userId;
    private BigDecimal amount;
}
</code></pre>

<h3 id="toc_42">2.2、创建Mapper</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo.mapper;

@Mapper
public interface OrderMapper extends BaseMapper&lt;Order&gt; {
}
</code></pre>

<h3 id="toc_43">2.3、配置垂直分片</h3>

<pre class="line-numbers"><code class="language-properties"># 应用名称
spring.application.name=sharding-jdbc-demo
# 环境设置
spring.profiles.active=dev

# 配置真实数据源
spring.shardingsphere.datasource.names=server-user,server-order

# 配置第 1 个数据源
spring.shardingsphere.datasource.server-user.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.server-user.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.server-user.jdbc-url=jdbc:mysql://192.168.100.201:3301/db_user
spring.shardingsphere.datasource.server-user.username=root
spring.shardingsphere.datasource.server-user.password=123456

# 配置第 2 个数据源
spring.shardingsphere.datasource.server-order.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.server-order.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.server-order.jdbc-url=jdbc:mysql://192.168.100.201:3302/db_order
spring.shardingsphere.datasource.server-order.username=root
spring.shardingsphere.datasource.server-order.password=123456

# 标准分片表配置（数据节点）
# spring.shardingsphere.rules.sharding.tables.&lt;table-name&gt;.actual-data-nodes=值
# 值由数据源名 + 表名组成，以小数点分隔。
# &lt;table-name&gt;：逻辑表名
spring.shardingsphere.rules.sharding.tables.t_user.actual-data-nodes=server-user.t_user
spring.shardingsphere.rules.sharding.tables.t_order.actual-data-nodes=server-order.t_order


# 打印SQL
spring.shardingsphere.props.sql-show=true

</code></pre>

<h2 id="toc_44">3、测试垂直分片</h2>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo;

@SpringBootTest
public class ShardingTest {


    @Autowired
    private UserMapper userMapper;

    @Autowired
    private OrderMapper orderMapper;

    /**
     * 垂直分片：插入数据测试
     */
    @Test
    public void testInsertOrderAndUser(){

        User user = new User();
        user.setUname(&quot;强哥&quot;);
        userMapper.insert(user);

        Order order = new Order();
        order.setOrderNo(&quot;ATGUIGU001&quot;);
        order.setUserId(user.getId());
        order.setAmount(new BigDecimal(100));
        orderMapper.insert(order);

    }

    /**
     * 垂直分片：查询数据测试
     */
    @Test
    public void testSelectFromOrderAndUser(){
        User user = userMapper.selectById(1L);
        Order order = orderMapper.selectById(1L);
    }
}
</code></pre>

<h3 id="toc_45">常见错误</h3>

<p><img src="assets/image-20220810163534068.png" alt="image-20220810163534068"/></p>

<p>ShardingSphere-JDBC远程连接的方式默认的密码加密规则是：mysql_native_password</p>

<p>因此需要在服务器端修改服务器的密码加密规则，如下：</p>

<pre class="line-numbers"><code class="language-sql">ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;
</code></pre>

<h1 id="toc_46">第06章 ShardingSphere-JDBC水平分片</h1>

<h2 id="toc_47">1、准备服务器</h2>

<p>服务器规划：使用<code>docker</code>方式创建如下容器</p>

<p><img src="assets/image-20220808033239206.png" alt="image-20220808033239206"/></p>

<ul>
<li><p>服务器：容器名<code>server-order0</code>，端口<code>3310</code></p></li>
<li><p>服务器：容器名<code>server-order1</code>，端口<code>3311</code></p></li>
</ul>

<h3 id="toc_48">1.1、创建server-order0容器</h3>

<ul>
<li><strong>step1：创建容器：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-shell">docker run -d \
-p 3310:3306 \
-v /atguigu/server/order0/conf:/etc/mysql/conf.d \
-v /atguigu/server/order0/data:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=123456 \
--name server-order0 \
mysql:8.0.29
</code></pre>

<ul>
<li><strong>step2：登录MySQL服务器：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-shell">#进入容器：
docker exec -it server-order0 env LANG=C.UTF-8 /bin/bash
#进入容器内的mysql命令行
mysql -uroot -p
#修改默认密码插件
ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;
</code></pre>

<ul>
<li><strong>step3：创建数据库：</strong></li>
</ul>

<p><code>注意：</code>水平分片的id需要在业务层实现，<code>不能依赖数据库的主键自增</code></p>

<pre class="line-numbers"><code class="language-sql">CREATE DATABASE db_order;
USE db_order;
CREATE TABLE t_order0 (
  id BIGINT,
  order_no VARCHAR(30),
  user_id BIGINT,
  amount DECIMAL(10,2),
  PRIMARY KEY(id) 
);
CREATE TABLE t_order1 (
  id BIGINT,
  order_no VARCHAR(30),
  user_id BIGINT,
  amount DECIMAL(10,2),
  PRIMARY KEY(id) 
);
</code></pre>

<h3 id="toc_49">1.2、创建server-order1容器</h3>

<ul>
<li><strong>step1：创建容器：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-shell">docker run -d \
-p 3311:3306 \
-v /atguigu/server/order1/conf:/etc/mysql/conf.d \
-v /atguigu/server/order1/data:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=123456 \
--name server-order1 \
mysql:8.0.29
</code></pre>

<ul>
<li><strong>step2：登录MySQL服务器：</strong></li>
</ul>

<pre class="line-numbers"><code class="language-shell">#进入容器：
docker exec -it server-order1 env LANG=C.UTF-8 /bin/bash
#进入容器内的mysql命令行
mysql -uroot -p
#修改默认密码插件
ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;
</code></pre>

<ul>
<li><strong>step3：创建数据库：</strong>和server-order0相同</li>
</ul>

<p><code>注意：</code>水平分片的id需要在业务层实现，不能依赖数据库的主键自增</p>

<pre class="line-numbers"><code class="language-sql">CREATE DATABASE db_order;
USE db_order;
CREATE TABLE t_order0 (
  id BIGINT,
  order_no VARCHAR(30),
  user_id BIGINT,
  amount DECIMAL(10,2),
  PRIMARY KEY(id) 
);
CREATE TABLE t_order1 (
  id BIGINT,
  order_no VARCHAR(30),
  user_id BIGINT,
  amount DECIMAL(10,2),
  PRIMARY KEY(id) 
);
</code></pre>

<h2 id="toc_50">2、基本水平分片</h2>

<h3 id="toc_51">2.1、基本配置</h3>

<pre class="line-numbers"><code class="language-properties">#========================基本配置
# 应用名称
spring.application.name=sharging-jdbc-demo
# 开发环境设置
spring.profiles.active=dev
# 内存模式
spring.shardingsphere.mode.type=Memory
# 打印SQl
spring.shardingsphere.props.sql-show=true
</code></pre>

<h3 id="toc_52">2.2、数据源配置</h3>

<pre class="line-numbers"><code class="language-properties">#========================数据源配置
# 配置真实数据源
spring.shardingsphere.datasource.names=server-user,server-order0,server-order1

# 配置第 1 个数据源
spring.shardingsphere.datasource.server-user.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.server-user.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.server-user.jdbc-url=jdbc:mysql://192.168.100.201:3301/db_user
spring.shardingsphere.datasource.server-user.username=root
spring.shardingsphere.datasource.server-user.password=123456

# 配置第 2 个数据源
spring.shardingsphere.datasource.server-order.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.server-order.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.server-order.jdbc-url=jdbc:mysql://192.168.100.201:3310/db_order
spring.shardingsphere.datasource.server-order.username=root
spring.shardingsphere.datasource.server-order.password=123456

# 配置第 3 个数据源
spring.shardingsphere.datasource.server-order.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.server-order.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.server-order.jdbc-url=jdbc:mysql://192.168.100.201:3311/db_order
spring.shardingsphere.datasource.server-order.username=root
spring.shardingsphere.datasource.server-order.password=123456
</code></pre>

<h3 id="toc_53">2.3、标椎分片表配置</h3>

<pre class="line-numbers"><code class="language-properties">#========================标准分片表配置（数据节点配置）
# spring.shardingsphere.rules.sharding.tables.&lt;table-name&gt;.actual-data-nodes=值
# 值由数据源名 + 表名组成，以小数点分隔。多个表以逗号分隔，支持 inline 表达式。
# &lt;table-name&gt;：逻辑表名
spring.shardingsphere.rules.sharding.tables.t_user.actual-data-nodes=server-user.t_user
spring.shardingsphere.rules.sharding.tables.t_order.actual-data-nodes=server-order0.t_order0,server-order0.t_order1,server-order1.t_order0,server-order1.t_order1
</code></pre>

<p>修改Order实体类的主键策略：</p>

<pre class="line-numbers"><code class="language-java">//@TableId(type = IdType.AUTO)//依赖数据库的主键自增策略
@TableId(type = IdType.ASSIGN_ID)//分布式id
</code></pre>

<p>测试：保留上面配置中的一个分片表节点分别进行测试，检查每个分片节点是否可用</p>

<pre class="line-numbers"><code class="language-java">/**
     * 水平分片：插入数据测试
     */
@Test
public void testInsertOrder(){

    Order order = new Order();
    order.setOrderNo(&quot;ATGUIGU001&quot;);
    order.setUserId(1L);
    order.setAmount(new BigDecimal(100));
    orderMapper.insert(order);
}
</code></pre>

<h3 id="toc_54">2.4、行表达式</h3>

<p>优化上一步的分片表配置</p>

<p><a href="https://shardingsphere.apache.org/document/5.1.1/cn/features/sharding/concept/inline-expression/">https://shardingsphere.apache.org/document/5.1.1/cn/features/sharding/concept/inline-expression/</a></p>

<pre class="line-numbers"><code class="language-properties">#========================标准分片表配置（数据节点配置）
# spring.shardingsphere.rules.sharding.tables.&lt;table-name&gt;.actual-data-nodes=值
# 值由数据源名 + 表名组成，以小数点分隔。多个表以逗号分隔，支持 inline 表达式。
# &lt;table-name&gt;：逻辑表名
spring.shardingsphere.rules.sharding.tables.t_user.actual-data-nodes=server-user.t_user
spring.shardingsphere.rules.sharding.tables.t_order.actual-data-nodes=server-order$-&gt;{0..1}.t_order$-&gt;{0..1}
</code></pre>

<h3 id="toc_55">2.5、分片算法配置</h3>

<p><strong>水平分库：</strong></p>

<p>分片规则：order表中<code>user_id</code>为偶数时，数据插入<code>server-order0服务器</code>，<code>user_id</code>为奇数时，数据插入<code>server-order1服务器</code>。这样分片的好处是，同一个用户的订单数据，一定会被插入到同一台服务器上，查询一个用户的订单时效率较高。</p>

<pre class="line-numbers"><code class="language-properties">#------------------------分库策略
# 分片列名称
spring.shardingsphere.rules.sharding.tables.t_order.database-strategy.standard.sharding-column=user_id
# 分片算法名称
spring.shardingsphere.rules.sharding.tables.t_order.database-strategy.standard.sharding-algorithm-name=alg_inline_userid

#------------------------分片算法配置
# 行表达式分片算法
# 分片算法类型
spring.shardingsphere.rules.sharding.sharding-algorithms.alg_inline_userid.type=INLINE
# 分片算法属性配置
spring.shardingsphere.rules.sharding.sharding-algorithms.alg_inline_userid.props.algorithm-expression=server-order$-&gt;{user_id % 2}

# 取模分片算法
# 分片算法类型
spring.shardingsphere.rules.sharding.sharding-algorithms.alg_mod.type=MOD
# 分片算法属性配置
spring.shardingsphere.rules.sharding.sharding-algorithms.alg_mod.props.sharding-count=2
</code></pre>

<p>为了方便测试，先设置只在 <code>t_order0</code>表上进行测试</p>

<pre class="line-numbers"><code class="language-properties">xxx.actual-data-nodes=server-order$-&gt;{0..1}.t_order0
</code></pre>

<p>测试：可以分别测试行表达式分片算法和取模分片算法</p>

<pre class="line-numbers"><code class="language-java">/**
     * 水平分片：分库插入数据测试
     */
@Test
public void testInsertOrderDatabaseStrategy(){

    for (long i = 0; i &lt; 4; i++) {
        Order order = new Order();
        order.setOrderNo(&quot;ATGUIGU001&quot;);
        order.setUserId(i + 1);
        order.setAmount(new BigDecimal(100));
        orderMapper.insert(order);
    }

}
</code></pre>

<p><strong>水平分表：</strong></p>

<p>分片规则：order表中<code>order_no的哈希值为偶数时</code>，数据插入对应服务器的<code>t_order0表</code>，<code>order_no的哈希值为奇数时</code>，数据插入对应服务器的<code>t_order1表</code>。因为order_no是字符串形式，因此不能直接取模。</p>

<pre class="line-numbers"><code class="language-properties">#------------------------分表策略
# 分片列名称
spring.shardingsphere.rules.sharding.tables.t_order.table-strategy.standard.sharding-column=order_no
# 分片算法名称
spring.shardingsphere.rules.sharding.tables.t_order.table-strategy.standard.sharding-algorithm-name=alg_hash_mod


#------------------------分片算法配置
# 哈希取模分片算法
# 分片算法类型
spring.shardingsphere.rules.sharding.sharding-algorithms.alg_hash_mod.type=HASH_MOD
# 分片算法属性配置
spring.shardingsphere.rules.sharding.sharding-algorithms.alg_hash_mod.props.sharding-count=2

</code></pre>

<p>测试前不要忘记将如下节点改回原来的状态</p>

<pre class="line-numbers"><code class="language-properties">xxx.actual-data-nodes=server-order$-&gt;{0..1}.t_order$-&gt;{0..1}
</code></pre>

<p>测试：</p>

<pre class="line-numbers"><code class="language-java">/**
     * 水平分片：分表插入数据测试
     */
@Test
public void testInsertOrderTableStrategy(){

    for (long i = 1; i &lt; 5; i++) {

        Order order = new Order();
        order.setOrderNo(&quot;ATGUIGU&quot; + i);
        order.setUserId(1L);
        order.setAmount(new BigDecimal(100));
        orderMapper.insert(order);
    }

    for (long i = 5; i &lt; 9; i++) {

        Order order = new Order();
        order.setOrderNo(&quot;ATGUIGU&quot; + i);
        order.setUserId(2L);
        order.setAmount(new BigDecimal(100));
        orderMapper.insert(order);
    }
}

/**
     * 测试哈希取模
     */
@Test
public void testHash(){

    //注意hash取模的结果是整个字符串hash后再取模，和数值后缀是奇数还是偶数无关
    System.out.println(&quot;ATGUIGU001&quot;.hashCode() % 2);
    System.out.println(&quot;ATGUIGU0011&quot;.hashCode() % 2);
}
</code></pre>

<p><strong>查询测试：</strong></p>

<pre class="line-numbers"><code class="language-java">/**
     * 水平分片：查询所有记录
     * 查询了两个数据源，每个数据源中使用UNION ALL连接两个表
     */
@Test
public void testShardingSelectAll(){

    List&lt;Order&gt; orders = orderMapper.selectList(null);
    orders.forEach(System.out::println);
}

/**
     * 水平分片：根据user_id查询记录
     * 查询了一个数据源，每个数据源中使用UNION ALL连接两个表
     */
@Test
public void testShardingSelectByUserId(){

    QueryWrapper&lt;Order&gt; orderQueryWrapper = new QueryWrapper&lt;&gt;();
    orderQueryWrapper.eq(&quot;user_id&quot;, 1L);
    List&lt;Order&gt; orders = orderMapper.selectList(orderQueryWrapper);
    orders.forEach(System.out::println);
}
</code></pre>

<h3 id="toc_56">2.6、分布式序列算法</h3>

<p><strong>雪花算法：</strong></p>

<p><a href="https://shardingsphere.apache.org/document/5.1.1/cn/features/sharding/concept/key-generator/">https://shardingsphere.apache.org/document/5.1.1/cn/features/sharding/concept/key-generator/</a></p>

<p>水平分片需要关注全局序列，因为不能简单的使用基于数据库的主键自增。</p>

<p>这里有两种方案：一种是基于MyBatisPlus的id策略；一种是ShardingSphere-JDBC的全局序列配置。</p>

<p><code>基于MyBatisPlus的id策略：</code>将Order类的id设置成如下形式</p>

<pre class="line-numbers"><code class="language-java">@TableId(type = IdType.ASSIGN_ID)
private Long id;
</code></pre>

<p><code>基于ShardingSphere-JDBC的全局序列配置</code>：和前面的MyBatisPlus的策略二选一</p>

<pre class="line-numbers"><code class="language-properties">#------------------------分布式序列策略配置
# 分布式序列列名称
spring.shardingsphere.rules.sharding.tables.t_order.key-generate-strategy.column=id
# 分布式序列算法名称
spring.shardingsphere.rules.sharding.tables.t_order.key-generate-strategy.key-generator-name=alg_snowflake

# 分布式序列算法配置
# 分布式序列算法类型
spring.shardingsphere.rules.sharding.key-generators.alg_snowflake.type=SNOWFLAKE
# 分布式序列算法属性配置
#spring.shardingsphere.rules.sharding.key-generators.alg_snowflake.props.xxx=
</code></pre>

<p>此时，需要将实体类中的id策略修改成以下形式：</p>

<pre class="line-numbers"><code class="language-java">//当配置了shardingsphere-jdbc的分布式序列时，自动使用shardingsphere-jdbc的分布式序列
//当没有配置shardingsphere-jdbc的分布式序列时，自动依赖数据库的主键自增策略
@TableId(type = IdType.AUTO)
</code></pre>

<h2 id="toc_57">3、多表关联</h2>

<h3 id="toc_58">3.1、创建关联表</h3>

<p>在<code>server-order0、server-order1</code>服务器中分别创建两张订单详情表<code>t_order_item0、t_order_item1</code></p>

<p>我们希望<code>同一个用户的订单表和订单详情表中的数据都在同一个数据源中，避免跨库关联</code>，因此这两张表我们使用相同的分片策略。</p>

<p>那么在<code>t_order_item</code>中我们也需要创建<code>order_no</code>和<code>user_id</code>这两个分片键</p>

<pre class="line-numbers"><code class="language-sql">CREATE TABLE t_order_item0(
    id BIGINT,
    order_no VARCHAR(30),
    user_id BIGINT,
    price DECIMAL(10,2),
    `count` INT,
    PRIMARY KEY(id)
);

CREATE TABLE t_order_item1(
    id BIGINT,
    order_no VARCHAR(30),
    user_id BIGINT,
    price DECIMAL(10,2),
    `count` INT,
    PRIMARY KEY(id)
);
</code></pre>

<h3 id="toc_59">3.2、创建实体类</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo.entity;

@TableName(&quot;t_order_item&quot;)
@Data
public class OrderItem {
    //当配置了shardingsphere-jdbc的分布式序列时，自动使用shardingsphere-jdbc的分布式序列
    @TableId(type = IdType.AUTO)
    private Long id;
    private String orderNo;
    private Long userId;
    private BigDecimal price;
    private Integer count;
}
</code></pre>

<h3 id="toc_60">3.3、创建Mapper</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shargingjdbcdemo.mapper;

@Mapper
public interface OrderItemMapper extends BaseMapper&lt;OrderItem&gt; {

}
</code></pre>

<h3 id="toc_61">3.4、配置关联表</h3>

<p>t_order_item的分片表、分片策略、分布式序列策略和t_order一致</p>

<pre class="line-numbers"><code class="language-properties">#------------------------标准分片表配置（数据节点配置）
spring.shardingsphere.rules.sharding.tables.t_order_item.actual-data-nodes=server-order$-&gt;{0..1}.t_order_item$-&gt;{0..1}

#------------------------分库策略
# 分片列名称
spring.shardingsphere.rules.sharding.tables.t_order_item.database-strategy.standard.sharding-column=user_id
# 分片算法名称
spring.shardingsphere.rules.sharding.tables.t_order_item.database-strategy.standard.sharding-algorithm-name=alg_mod

#------------------------分表策略
# 分片列名称
spring.shardingsphere.rules.sharding.tables.t_order_item.table-strategy.standard.sharding-column=order_no
# 分片算法名称
spring.shardingsphere.rules.sharding.tables.t_order_item.table-strategy.standard.sharding-algorithm-name=alg_hash_mod

#------------------------分布式序列策略配置
# 分布式序列列名称
spring.shardingsphere.rules.sharding.tables.t_order_item.key-generate-strategy.column=id
# 分布式序列算法名称
spring.shardingsphere.rules.sharding.tables.t_order_item.key-generate-strategy.key-generator-name=alg_snowflake
</code></pre>

<h3 id="toc_62">3.5、测试插入数据</h3>

<p>同一个用户的订单表和订单详情表中的数据都在同一个数据源中，避免跨库关联</p>

<pre class="line-numbers"><code class="language-java">/**
     * 测试关联表插入
     */
@Test
public void testInsertOrderAndOrderItem(){

    for (long i = 1; i &lt; 3; i++) {

        Order order = new Order();
        order.setOrderNo(&quot;ATGUIGU&quot; + i);
        order.setUserId(1L);
        orderMapper.insert(order);

        for (long j = 1; j &lt; 3; j++) {
            OrderItem orderItem = new OrderItem();
            orderItem.setOrderNo(&quot;ATGUIGU&quot; + i);
            orderItem.setUserId(1L);
            orderItem.setPrice(new BigDecimal(10));
            orderItem.setCount(2);
            orderItemMapper.insert(orderItem);
        }
    }

    for (long i = 5; i &lt; 7; i++) {

        Order order = new Order();
        order.setOrderNo(&quot;ATGUIGU&quot; + i);
        order.setUserId(2L);
        orderMapper.insert(order);

        for (long j = 1; j &lt; 3; j++) {
            OrderItem orderItem = new OrderItem();
            orderItem.setOrderNo(&quot;ATGUIGU&quot; + i);
            orderItem.setUserId(2L);
            orderItem.setPrice(new BigDecimal(1));
            orderItem.setCount(3);
            orderItemMapper.insert(orderItem);
        }
    }

}
</code></pre>

<h2 id="toc_63">4、绑定表</h2>

<p><strong>需求：</strong>查询每个订单的订单号和总订单金额</p>

<h3 id="toc_64">4.1、创建VO对象</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo.entity;

@Data
public class OrderVo {
    private String orderNo;
    private BigDecimal amount;
}
</code></pre>

<h3 id="toc_65">4.2、添加Mapper方法</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo.mapper;

@Mapper
public interface OrderMapper extends BaseMapper&lt;Order&gt; {

    @Select({&quot;SELECT o.order_no, SUM(i.price * i.count) AS amount&quot;,
            &quot;FROM t_order o JOIN t_order_item i ON o.order_no = i.order_no&quot;,
            &quot;GROUP BY o.order_no&quot;})
    List&lt;OrderVo&gt; getOrderAmount();

}
</code></pre>

<h3 id="toc_66">4.3、测试关联查询</h3>

<pre class="line-numbers"><code class="language-java">/**
     * 测试关联表查询
     */
@Test
public void testGetOrderAmount(){

    List&lt;OrderVo&gt; orderAmountList = orderMapper.getOrderAmount();
    orderAmountList.forEach(System.out::println);
}
</code></pre>

<h3 id="toc_67">4.4、配置绑定表</h3>

<p>在原来水平分片配置的基础上添加如下配置：</p>

<pre class="line-numbers"><code class="language-properties">#------------------------绑定表
spring.shardingsphere.rules.sharding.binding-tables[0]=t_order,t_order_item
</code></pre>

<p>配置完绑定表后再次进行关联查询的测试：</p>

<ul>
<li><p><strong>如果不配置绑定表：测试的结果为8个SQL。</strong>多表关联查询会出现笛卡尔积关联。</p></li>
<li><p><strong>如果配置绑定表：测试的结果为4个SQL。</strong> 多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升。</p></li>
</ul>

<p><code>绑定表：</code>指分片规则一致的一组分片表。 使用绑定表进行多表关联查询时，必须使用分片键进行关联，否则会出现笛卡尔积关联或跨库关联，从而影响查询效率。</p>

<h2 id="toc_68">5、广播表</h2>

<h3 id="toc_69">4.1、什么是广播表</h3>

<p>指所有的分片数据源中都存在的表，表结构及其数据在每个数据库中均完全一致。 适用于数据量不大且需要与海量数据的表进行关联查询的场景，例如：字典表。</p>

<p>广播具有以下特性：</p>

<p>（1）插入、更新操作会实时在所有节点上执行，保持各个分片的数据一致性</p>

<p>（2）查询操作，只从一个节点获取</p>

<p>（3）可以跟任何一个表进行 JOIN 操作</p>

<h3 id="toc_70">4.2、创建广播表</h3>

<p>在server-order0、server-order1和server-user服务器中分别创建t_dict表</p>

<pre class="line-numbers"><code class="language-sql">CREATE TABLE t_dict(
    id BIGINT,
    dict_type VARCHAR(200),
    PRIMARY KEY(id)
);
</code></pre>

<h3 id="toc_71">4.3、程序实现</h3>

<h4 id="toc_72">4.3.1、创建实体类</h4>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo.entity;

@TableName(&quot;t_dict&quot;)
@Data
public class Dict {
    //可以使用MyBatisPlus的雪花算法
    @TableId(type = IdType.ASSIGN_ID)
    private Long id;
    private String dictType;
}
</code></pre>

<h4 id="toc_73">4.3.2、创建Mapper</h4>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingjdbcdemo.mapper;

@Mapper
public interface DictMapper extends BaseMapper&lt;Dict&gt; {
}
</code></pre>

<h4 id="toc_74">4.3.3、配置广播表</h4>

<pre class="line-numbers"><code class="language-properties">#数据节点可不配置，默认情况下，向所有数据源广播
spring.shardingsphere.rules.sharding.tables.t_dict.actual-data-nodes=server-user.t_dict,server-order$-&gt;{0..1}.t_dict

# 广播表
spring.shardingsphere.rules.sharding.broadcast-tables[0]=t_dict
</code></pre>

<h3 id="toc_75">4.4、测试广播表</h3>

<pre class="line-numbers"><code class="language-java">@Autowired
private DictMapper dictMapper;

/**
     * 广播表：每个服务器中的t_dict同时添加了新数据
     */
@Test
public void testBroadcast(){

    Dict dict = new Dict();
    dict.setDictType(&quot;type1&quot;);
    dictMapper.insert(dict);
}

/**
     * 查询操作，只从一个节点获取数据
     * 随机负载均衡规则
     */
@Test
public void testSelectBroadcast(){

    List&lt;Dict&gt; dicts = dictMapper.selectList(null);
    dicts.forEach(System.out::println);
}
</code></pre>

<h1 id="toc_76">第07章 启动ShardingSphere-Proxy</h1>

<h2 id="toc_77">1、获取</h2>

<p>目前 ShardingSphere-Proxy 提供了 3 种获取方式：</p>

<ul>
<li><a href="https://shardingsphere.apache.org/document/5.1.1/cn/user-manual/shardingsphere-proxy/startup/bin/">二进制发布包</a></li>
<li><a href="https://shardingsphere.apache.org/document/5.1.1/cn/user-manual/shardingsphere-proxy/startup/docker/">Docker</a></li>
<li><a href="https://shardingsphere.apache.org/document/5.1.1/cn/user-manual/shardingsphere-proxy/startup/helm/">Helm</a></li>
</ul>

<h2 id="toc_78">2、使用二进制发布包安装</h2>

<p>二进制包既可以Linux系统运行，又可以在windows系统运行</p>

<p><strong>step1：解压二进制包</strong></p>

<p><code>apache-shardingsphere-5.1.1-shardingsphere-proxy-bin.tar.gz</code></p>

<p>windows：使用解压软件解压文件</p>

<p>Linux：将文件上传至/opt目录，并解压</p>

<pre class="line-numbers"><code class="language-shell">tar -zxvf apache-shardingsphere-5.1.1-shardingsphere-proxy-bin.tar.gz
</code></pre>

<p><strong>step2：MySQL驱动</strong></p>

<p><code>mysql-connector-java-8.0.22.jar</code></p>

<p>将MySQl驱动放至解压目录中的<code>ext-lib</code>目录</p>

<p><strong>spte3：修改配置conf/server.yaml</strong></p>

<pre class="line-numbers"><code class="language-yaml">rules:
  - !AUTHORITY
    users:
      - root@%:root
    provider:
      type: ALL_PRIVILEGES_PERMITTED

props:
  sql-show: true
</code></pre>

<p><strong>spte4：启动ShardingSphere-Proxy</strong></p>

<p>Linux 操作系统请运行 <code>bin/start.sh</code></p>

<p>Windows 操作系统请运行 <code>bin/start.bat</code> </p>

<p>指定端口号和配置文件目录：<code>bin/start.bat ${proxy_port} ${proxy_conf_directory}</code> </p>

<p><strong>step5：远程连接ShardingSphere-Proxy</strong></p>

<p>远程访问</p>

<pre class="line-numbers"><code class="language-shell">mysql -h192.168.100.1 -P3307 -uroot -p
</code></pre>

<p><strong>step6：访问测试</strong></p>

<pre class="line-numbers"><code class="language-sql">show databases;
</code></pre>

<p><img src="assets/image-20220819152009158.png" alt="image-20220819152009158"/></p>

<h2 id="toc_79">3、使用Docker安装</h2>

<p><strong>step1：启动Docker容器</strong></p>

<pre class="line-numbers"><code class="language-shell">docker run -d \
-v /atguigu/server/proxy-a/conf:/opt/shardingsphere-proxy/conf \
-v /atguigu/server/proxy-a/ext-lib:/opt/shardingsphere-proxy/ext-lib \
-e ES_JAVA_OPTS=&quot;-Xmx256m -Xms256m -Xmn128m&quot; \
-p 3321:3307 \
--name server-proxy-a \
apache/shardingsphere-proxy:5.1.1
</code></pre>

<p><strong>step2：上传MySQL驱动</strong></p>

<p>将MySQl驱动上传至<code>/atguigu/server/proxy-a/ext-lib</code>目录</p>

<p><strong>spte3：修改配置server.yaml</strong></p>

<pre class="line-numbers"><code class="language-yaml">rules:
  - !AUTHORITY
    users:
      - root@%:root
    provider:
      type: ALL_PRIVILEGES_PERMITTED

props:
  sql-show: true
</code></pre>

<p>将配置文件上传至<code>/atguigu/server/proxy-a/conf</code>目录</p>

<p><strong>spte4：重启容器</strong></p>

<pre class="line-numbers"><code class="language-shell">docker restart server-proxy-a
</code></pre>

<p><strong>step5：远程连接ShardingSphere-Proxy</strong></p>

<p>ShardingSphere-Proxy容器中默认情况下没有mysql命令行客户端的安装，因此需要远程访问</p>

<pre class="line-numbers"><code class="language-shell">mysql -h192.168.100.201 -P3321 -uroot -p
</code></pre>

<p><strong>step6：访问测试</strong></p>

<pre class="line-numbers"><code class="language-sql">show databases;
</code></pre>

<p><img src="assets/image-20220819152009158.png" alt="image-20220819152009158"/></p>

<p><strong>常见问题：docker容器无法远程连接</strong></p>

<p>容器可以成功的创建并启动，但是无法远程连接。排除防火墙和网络等问题后，看看是不是因为容器内存不足导致。</p>

<p><code>原因：</code>容器可分配内存不足</p>

<p><code>查看办法：</code>进入容器后查看ShardingSphere-Proxy的日志，如有有<code>cannot allocate memory</code>，则说明容器内存不足</p>

<pre class="line-numbers"><code class="language-shell">docker exec -it server-proxy-a env LANG=C.UTF-8 /bin/bash
cd /opt/shardingsphere-proxy/logs
tail stdout.log 
</code></pre>

<p><img src="assets/image-20220819151154763.png" alt="image-20220819151154763"/></p>

<p><code>解决方案：</code>创建容器的时候使用JVM参数</p>

<pre class="line-numbers"><code class="language-shell">-e ES_JAVA_OPTS=&quot;-Xmx256m -Xms256m -Xmn128m&quot;
</code></pre>

<h1 id="toc_80">第08章 ShardingSphere-Proxy读写分离</h1>

<h2 id="toc_81">1、修改配置文件</h2>

<p><strong>修改配置config-readwrite-splitting.yaml</strong></p>

<pre class="line-numbers"><code class="language-yaml">schemaName: readwrite_splitting_db

dataSources:
  write_ds:
    url: jdbc:mysql://192.168.100.201:3306/db_user?serverTimezone=UTC&amp;useSSL=false
    username: root
    password: 123456
    connectionTimeoutMilliseconds: 30000
    idleTimeoutMilliseconds: 60000
    maxLifetimeMilliseconds: 1800000
    maxPoolSize: 50
    minPoolSize: 1
  read_ds_0:
    url: jdbc:mysql://192.168.100.201:3307/db_user?serverTimezone=UTC&amp;useSSL=false
    username: root
    password: 123456
    connectionTimeoutMilliseconds: 30000
    idleTimeoutMilliseconds: 60000
    maxLifetimeMilliseconds: 1800000
    maxPoolSize: 50
    minPoolSize: 1
  read_ds_1:
    url: jdbc:mysql://192.168.100.201:3308/db_user?serverTimezone=UTC&amp;useSSL=false
    username: root
    password: 123456
    connectionTimeoutMilliseconds: 30000
    idleTimeoutMilliseconds: 60000
    maxLifetimeMilliseconds: 1800000
    maxPoolSize: 50
    minPoolSize: 1

rules:
- !READWRITE_SPLITTING
  dataSources:
    readwrite_ds:
      type: Static
      props:
        write-data-source-name: write_ds
        read-data-source-names: read_ds_0,read_ds_1
</code></pre>

<p>将配置文件上传至<code>/atguigu/server/proxy-a/conf</code>目录</p>

<p><strong>重启容器</strong></p>

<pre class="line-numbers"><code class="language-shell">docker restart server-proxy-a
</code></pre>

<h2 id="toc_82">2、实时查看日志</h2>

<p>可以通过这种方式查看服务器中输出的SQL语句</p>

<pre class="line-numbers"><code class="language-shell">docker exec -it server-proxy-a env LANG=C.UTF-8 /bin/bash
tail -f /opt/shardingsphere-proxy/logs/stdout.log 
</code></pre>

<h2 id="toc_83">3、远程访问测试</h2>

<pre class="line-numbers"><code class="language-sql">mysql&gt; show databases;
mysql&gt; use readwrite_splitting_db;
mysql&gt; show tables;
mysql&gt; select * from t_user;
mysql&gt; select * from t_user;
mysql&gt; insert into t_user(uname) values(&#39;wang5&#39;);
</code></pre>

<h2 id="toc_84">4、应用程序访问Proxy</h2>

<h3 id="toc_85">4.1、创建项目</h3>

<p>项目类型：Spring Initializr</p>

<p>SpringBoot脚手架：<a href="http://start.aliyun.com">http://start.aliyun.com</a></p>

<p>项目名：sharding-proxy-demo</p>

<p>SpringBoot版本：2.3.7.RELEASE</p>

<h3 id="toc_86">4.2、添加依赖</h3>

<pre class="line-numbers"><code class="language-markup">&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;mysql&lt;/groupId&gt;
        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
        &lt;scope&gt;runtime&lt;/scope&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
        &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
        &lt;version&gt;3.3.1&lt;/version&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
        &lt;artifactId&gt;lombok&lt;/artifactId&gt;
        &lt;optional&gt;true&lt;/optional&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
        &lt;scope&gt;test&lt;/scope&gt;
        &lt;exclusions&gt;
            &lt;exclusion&gt;
                &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt;
                &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt;
            &lt;/exclusion&gt;
        &lt;/exclusions&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>

<h3 id="toc_87">4.3、创建实体类</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingproxydemo.entity;

@TableName(&quot;t_user&quot;)
@Data
public class User {
    @TableId(type = IdType.AUTO)
    private Long id;
    private String uname;
}

</code></pre>

<h3 id="toc_88">4.4、创建Mapper</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingproxydemo.mapper;

@Mapper
public interface UserMapper extends BaseMapper&lt;User&gt; {
}
</code></pre>

<h3 id="toc_89">4.5、配置数据源</h3>

<pre class="line-numbers"><code class="language-properties"># 应用名称
spring.application.name=sharding-proxy-demo
# 开发环境设置
spring.profiles.active=dev

#mysql数据库连接（proxy）
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://192.168.100.201:3321/readwrite_splitting_db?serverTimezone=GMT%2B8&amp;useSSL=false
spring.datasource.username=root
spring.datasource.password=root

#mybatis日志
mybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl
</code></pre>

<h3 id="toc_90">4.6、测试</h3>

<pre class="line-numbers"><code class="language-java">package com.atguigu.shardingproxydemo;

@SpringBootTest
class ShardingProxyDemoApplicationTests {

    @Autowired
    private UserMapper userMapper;

    /**
     * 读数据测试
     */
    @Test
    public void testSelectAll(){
        List&lt;User&gt; users = userMapper.selectList(null);
        users.forEach(System.out::println);
    }
}
</code></pre>

<h1 id="toc_91">第09章 ShardingSphere-Proxy垂直分片</h1>

<h2 id="toc_92">1、修改配置文件</h2>

<p><strong>修改配置config-sharding.yaml</strong></p>

<pre class="line-numbers"><code class="language-yaml">schemaName: sharding_db

dataSources:
  ds_0:
    url: jdbc:mysql://192.168.100.201:3301/db_user?serverTimezone=UTC&amp;useSSL=false
    username: root
    password: 123456
    connectionTimeoutMilliseconds: 30000
    idleTimeoutMilliseconds: 60000
    maxLifetimeMilliseconds: 1800000
    maxPoolSize: 50
    minPoolSize: 1
  ds_1:
    url: jdbc:mysql://192.168.100.201:3302/db_order?serverTimezone=UTC&amp;useSSL=false
    username: root
    password: 123456
    connectionTimeoutMilliseconds: 30000
    idleTimeoutMilliseconds: 60000
    maxLifetimeMilliseconds: 1800000
    maxPoolSize: 50
    minPoolSize: 1

rules:
- !SHARDING
  tables:
    t_user:
      actualDataNodes: ds_0.t_user
    t_order:
      actualDataNodes: ds_1.t_order
</code></pre>

<h2 id="toc_93">2、实时查看日志</h2>

<p>可以通过这种方式查看服务器中输出的SQL语句</p>

<pre class="line-numbers"><code class="language-shell">docker exec -it server-proxy-a env LANG=C.UTF-8 /bin/bash
tail -f /opt/shardingsphere-proxy/logs/stdout.log 
</code></pre>

<h2 id="toc_94">3、远程访问测试</h2>

<pre class="line-numbers"><code class="language-sql">mysql&gt; show databases;
mysql&gt; use sharding_db;
mysql&gt; show tables;
mysql&gt; select * from t_order;
mysql&gt; select * from t_user;
</code></pre>

<h1 id="toc_95">第10章 ShardingSphere-Proxy水平分片</h1>

<h2 id="toc_96">1、修改配置文件</h2>

<p><strong>修改配置config-sharding.yaml</strong></p>

<pre class="line-numbers"><code class="language-yaml">schemaName: sharding_db

dataSources:
  ds_user:
    url: jdbc:mysql://192.168.100.201:3301/db_user?serverTimezone=UTC&amp;useSSL=false
    username: root
    password: 123456
    connectionTimeoutMilliseconds: 30000
    idleTimeoutMilliseconds: 60000
    maxLifetimeMilliseconds: 1800000
    maxPoolSize: 50
    minPoolSize: 1
  ds_order0:
    url: jdbc:mysql://192.168.100.201:3310/db_order?serverTimezone=UTC&amp;useSSL=false
    username: root
    password: 123456
    connectionTimeoutMilliseconds: 30000
    idleTimeoutMilliseconds: 60000
    maxLifetimeMilliseconds: 1800000
    maxPoolSize: 50
    minPoolSize: 1
  ds_order1:
    url: jdbc:mysql://192.168.100.201:3311/db_order?serverTimezone=UTC&amp;useSSL=false
    username: root
    password: 123456
    connectionTimeoutMilliseconds: 30000
    idleTimeoutMilliseconds: 60000
    maxLifetimeMilliseconds: 1800000
    maxPoolSize: 50
    minPoolSize: 1

rules:
- !SHARDING
  tables:
    t_user:
      actualDataNodes: ds_user.t_user

    t_order:
      actualDataNodes: ds_order${0..1}.t_order${0..1}
      databaseStrategy:
        standard:
          shardingColumn: user_id
          shardingAlgorithmName: alg_mod
      tableStrategy:
        standard:
          shardingColumn: order_no
          shardingAlgorithmName: alg_hash_mod
      keyGenerateStrategy:
        column: id
        keyGeneratorName: snowflake
    t_order_item:
      actualDataNodes: ds_order${0..1}.t_order_item${0..1}
      databaseStrategy:
        standard:
          shardingColumn: user_id
          shardingAlgorithmName: alg_mod
      tableStrategy:
        standard:
          shardingColumn: order_no
          shardingAlgorithmName: alg_hash_mod
      keyGenerateStrategy:
        column: id
        keyGeneratorName: snowflake

  bindingTables:
    - t_order,t_order_item


  broadcastTables:
    - t_dict

  shardingAlgorithms:
    alg_inline_userid:
      type: INLINE
      props:
        algorithm-expression: server-order$-&gt;{user_id % 2}
    alg_mod:
      type: MOD
      props:
        sharding-count: 2
    alg_hash_mod:
      type: HASH_MOD
      props:
        sharding-count: 2
  
  keyGenerators:
    snowflake:
      type: SNOWFLAKE

</code></pre>

<h2 id="toc_97">2、实时查看日志</h2>

<p>可以通过这种方式查看服务器中输出的SQL语句</p>

<pre class="line-numbers"><code class="language-shell">docker exec -it server-proxy-a env LANG=C.UTF-8 /bin/bash
tail -f /opt/shardingsphere-proxy/logs/stdout.log 
</code></pre>

<h2 id="toc_98">3、远程访问测试</h2>

<pre class="line-numbers"><code class="language-sql">mysql&gt; show databases;
mysql&gt; use sharding_db;
mysql&gt; show tables;
mysql&gt; select * from t_order; --测试水平分片
mysql&gt; select * from t_dict; --测试广播表
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL修改表名大小写敏感配置时，一定要注意这个问题]]></title>
    <link href="https://penghuicai.github.io/16768818963496.html"/>
    <updated>2023-02-20T16:31:36+08:00</updated>
    <id>https://penghuicai.github.io/16768818963496.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">查询表名大小写敏感设置</h2>

<pre class="line-numbers"><code class="language-text"># 指定表名是否使用小写
show GLOBAL VARIABLES like &#39;lower_case_table_names&#39;;
</code></pre>

<p><code>1</code>表名全部转化为小写。<br/>
<code>0</code>表名是严格区分大小写的，若查询时大小写弄混淆就会直接报错表不存在。</p>

<h2 id="toc_1">修改表名大小写敏感前注意事项</h2>

<p>严格区分大小写<code>0</code>改为<code>1</code>全部转为小写的时候，如果<code>表名</code>中<code>出现任意一个大写字母</code>，都需要将其改为小写之，之后再修改配置。<br/>
否者<code>存在大写字母的表</code>会报<code>doesn&#39;t exist</code>的错误，导致系统无法正常运行。</p>

<pre class="line-numbers"><code class="language-sql"># 查询所有包含大写字母的表
SELECT 
    TABLE_SCHEMA,
    TABLE_NAME
FROM 
    information_schema.`TABLES` 
WHERE table_type != &#39;SYSTEM VIEW&#39; 
    AND TABLE_NAME REGEXP BINARY &#39;[a-z]&#39;

# 将大写表重命名为小写表 
RENAME table TEST to test;

# 若存在大写库 则需要先创建小写库 然后将大写库里面的表转移到小写库
RENAME table TESTDB.test_tb to testdb.test_tb;

# 拼接SQL 将大写库中的表转移到小写库
SELECT
    CONCAT( &#39;rename table TESTDB.&#39;, TABLE_NAME, &#39; to testdb.&#39;, TABLE_NAME, &#39;;&#39; ) 
FROM
    information_schema.TABLES 
WHERE
    TABLE_SCHEMA = &#39;TESTDB&#39;;

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[系统架构的发展过程]]></title>
    <link href="https://penghuicai.github.io/16762779297017.html"/>
    <updated>2023-02-13T16:45:29+08:00</updated>
    <id>https://penghuicai.github.io/16762779297017.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">传统架构</h2>

<h3 id="toc_1">单一应用架构/单体架构</h3>

<p>当网站流量很小时，简单单体结构，只需一个应用，将所有功能都部署在一起，运行在一个服务器上，以减少部署节点和成本。数据访问框架(ORM)是关键。</p>

<ol>
<li>特点：
<ul>
<li>所有功能集成一个项目中</li>
<li>所有功能打一个包就能完成</li>
<li>应用与数据库分开部署</li>
<li>通过部署应用集群和数据集群来提供性能</li>
</ul></li>
<li>优势：
<ul>
<li>开发相当简单</li>
<li>部署单一应用程序是很简单，只需将打包的应用程序复制到服务器</li>
<li>横向扩展是很简单的。即：如果一台服务器不够用，则可以再部署一台全新的服务器，并且可以通过负载均衡器【例如Nginx】将负载分配到不同的服务器上。</li>
</ul></li>
<li>劣势：
<ul>
<li>复杂性高，大项目整个项目包含的模块多，模块边界模糊，依赖关系不清晰，代码质量参差不齐，混乱的堆砌在一起，整个项目非常复杂，每次修改代码都胆战心惊，有时候就是仅仅新增了一个简单的功能，或者就是修改一个bug都会带来隐含的缺陷。</li>
<li>灵活性，单一架构不够灵活。技术从一开始就决定了，并自始至终遵循。一旦开发成熟，有时就很难升级技术堆栈版本，更不用说增量地采用新技术了。</li>
<li>可靠性，不可靠。如果一个特性出现故障，整个应用程序可能会出现故障</li>
<li>开发速度，单一架构的大型项目开发缓慢，对于新的团队成员来说，理解和修改大型单一架构应用程序的代码是很困难的。代码质量会随着时间的推移而下降，应用程序越大，启动时间越长。</li>
<li>不利于升级维护：某一个模块出现问题，则导致整个项目整体部署。</li>
</ul></li>
</ol>

<h3 id="toc_2">垂直应用框架</h3>

<p>MVC模式、前后端分离模式、组件模式、类库模式、当业务规模较小时，把所有应用部署到同一个进程，通过双机或者前置负载均衡实现负载分流，或者大项目垂直拆分业务为一个个小项目，此时分离前后端是逻辑的MVC架构是关键。</p>

<ol>
<li>特点：
<ul>
<li>以单体架构的大规模项目，进行垂直划分项目，将大项目拆分成一个个单体结构项目</li>
<li>项目与项目之前的存在数据冗余，耦合性较大</li>
<li>项目之间的接口多为数据同步功能</li>
</ul></li>
<li>优点：
<ul>
<li>项目架构简单，前期开发成本低，周期短，小型项目的首选</li>
<li>通过垂直拆分，原来的单体项目不至于无限放大</li>
<li>不同的项目可以采用不同的技术</li>
</ul></li>
<li>缺点：
<ul>
<li>系统之间相互独立，有重复的开发任务</li>
<li>系统性能扩展只能通过扩展集群节点，成本高，有瓶颈</li>
</ul></li>
</ol>

<h2 id="toc_3">分布式架构</h2>

<h3 id="toc_4">面向服务的体系结构(SOA，service-oriented architecture)</h3>

<p>垂直应用越来越多时，重复的代码量也会递增，所以出现了分布式架构，它将工程拆分为表现层和服务层两个部分，服务层中包含业务逻辑，表层只需要处理和页面的交互，业务逻辑都是调用服务层的服务来实现，此时提升业务复用性和拆分是关键，RPC和MQ是SOA的两大基石。（RPC，Remote Procedure Call 远程过程调用）是一个计算机面向方法的通信协议。 该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。A计算机提供一个服务，B计算机同过参数传递的方式可以像调用本地服务那样调用A计算机的服务。</p>

<ol>
<li>特点:
<ul>
<li>该定义并不特指一种技术，而是一种分布式运算的软件设计方法。软件的部分组件（调用者），可以透过网络上的通用协议调用另一个应用软件组件运行、运作，让调用者获得服务。</li>
<li>基于SOA思想将重复、公共的功能抽取为组件，以服务方式给各个系统提供服务</li>
<li>各个项目（系统）与服务之间采用webService、RPC等方式通讯</li>
</ul></li>
<li>优点：
<ul>
<li>将重复、公共的功能抽取为服务，提高开发效率，提高系统的可复用性，可维护性</li>
<li>可以针对不同服务的特点指定集群及优化方案。</li>
<li>基于ESB/DUBBO减少系统耦合</li>
</ul></li>
<li>缺点：
<ul>
<li>系统与服务界限模糊，不利于开发和维护；</li>
<li>抽象服务的粒度过大，系统与服务之间耦合性高。</li>
</ul></li>
</ol>

<h3 id="toc_5">微服务架构（MSA，MicroServices Architecture）</h3>

<p>微服务架构和分布式SOA架构有一点类似，但是区别也很明显，SOA是面向服务的架构，从顶层的应用到底层的数据库设计都是基于应用来设计，但是微服务是将服务原子化，独立拆分成各个独立的系统。</p>

<ol>
<li>优点：
<ul>
<li>去中心化，通过服务的原子化拆分，以及微服务的独立打包、部署和升级，小团队的交付周期将缩短，运维成本也将大幅度下降；</li>
<li>微服务遵循单一原则。微服务之间采用Restful等轻量协议传输。</li>
<li>产品迭代周期更短，业务迭代快</li>
</ul></li>
<li>缺点：
<ul>
<li>微服务过多，服务治理成本高，不利于系统维护；</li>
<li>业务发展比较稳定其实并不建议使用微服务架构，通讯成本增加，架构复杂增加；</li>
<li>分布式系统开发的技术成本高（容错、分布式事务等），对团队挑战大。</li>
</ul></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[删除JOB日志]]></title>
    <link href="https://penghuicai.github.io/16759135328486.html"/>
    <updated>2023-02-09T11:32:12+08:00</updated>
    <id>https://penghuicai.github.io/16759135328486.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">统计JOB日志数据</h2>

<pre class="line-numbers"><code class="language-text">SELECT {CronJob.code},count(1) FROM {LogFile
JOIN CronJob ON {CronJob.pk} = {owner}
} WHERE {location} LIKE &#39;cronjob%&#39; GROUP BY {owner}

SELECT {CronJob.code}, count(1) FROM {LogFile
JOIN CronJob ON {CronJob.pk} = {owner}
} WHERE {CronJob.code} = &#39;HepRefundAutoAgreeReturnCronJob&#39; AND {location} LIKE &#39;cronjob%&#39; 
</code></pre>

<h2 id="toc_1">删除job日志</h2>

<pre class="line-numbers"><code class="language-text">REMOVE LogFile[batchmode=true];owner(code)[unique=true];
;jobcode;
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IDEA 常用插件]]></title>
    <link href="https://penghuicai.github.io/16668551965194.html"/>
    <updated>2022-10-27T15:19:56+08:00</updated>
    <id>https://penghuicai.github.io/16668551965194.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0"><a href="https://plugins.jetbrains.com/plugin/7499-gittoolbox">GitToolBox</a></h2>

<h2 id="toc_1"><a href="https://plugins.jetbrains.com/search?search=RestfulToolKit">RestfulToolKit</a></h2>

<p>注意：把web项目设置成源代码，才根据URL查询Controller<br/>
<img src="media/16668551965194/16668561002173.jpg" alt="" style="width:1233px;"/></p>

<h2 id="toc_2"><a href="https://plugins.jetbrains.com/plugin/7160-camelcase">CamelCase</a></h2>

<h2 id="toc_3"><a href="https://plugins.jetbrains.com/plugin/8579-translation?1=20221031001427687&amp;2=K8Lo5P94e5k9YrBgRxYJ">Translation</a></h2>

<h2 id="toc_4"><a href="https://plugins.jetbrains.com/plugin/13710-chinese-simplified-language-pack----">Chinese ​(Simplified)​ Language Pack / 中文语言包</a></h2>

<h2 id="toc_5"><a href="https://plugins.jetbrains.com/plugin/10080-rainbow-brackets">Rainbow Brackets</a></h2>

<h2 id="toc_6"><a href="https://plugins.jetbrains.com/plugin/10044-atom-material-icons">Atom Material File Icons</a></h2>

<h2 id="toc_7"><a href="https://plugins.jetbrains.com/plugin/13574-aixcoder-code-completer">AiXcoder Code Completer</a></h2>

<h2 id="toc_8"><a href="https://plugins.jetbrains.com/plugin/18824-codeglance-pro">CodeGlance Pro</a></h2>

<h2 id="toc_9"><a href="https://plugins.jetbrains.com/plugin/7125-grep-console">Grep Console</a></h2>

<h2 id="toc_10"><a href="https://plugins.jetbrains.com/plugin/17320-highlightbracketpair">HighlightBracketPair</a></h2>

<h2 id="toc_11"><a href="https://plugins.jetbrains.com/plugin/9792-key-promoter-x">Key Promoter X</a></h2>

<h2 id="toc_12"><a href="https://plugins.jetbrains.com/plugin/7345-presentation-assistant">Presentation Assistant</a></h2>

<h2 id="toc_13"><a href="https://plugins.jetbrains.com/plugin/12867-sap-commerce-developers-toolset">SAP Commerce Developers Toolset</a></h2>

<h2 id="toc_14">设置</h2>

<h3 id="toc_15">常量字符串过长</h3>

<p><img src="media/16668551965194/16672984887608.jpg" alt="" style="width:979px;"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IDEA 常用Java自定义模板快捷输入]]></title>
    <link href="https://penghuicai.github.io/16668544609244.html"/>
    <updated>2022-10-27T15:07:40+08:00</updated>
    <id>https://penghuicai.github.io/16668544609244.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">注意部分冲突，可去掉相关勾选</h2>

<p><img src="media/16668544609244/16668544949671.jpg" alt="" style="width:1244px;"/></p>

<h2 id="toc_1">logg</h2>

<pre class="line-numbers"><code class="language-java"># logg
# 日志快速创建
# 编辑变量 NAME 表达式 className()
# 适用于Java:声明

# 模板内容
private static final org.slf4j.Logger LOG = org.slf4j.LoggerFactory.getLogger($NAME$.class);
</code></pre>

<h2 id="toc_2">logi</h2>

<pre class="line-numbers"><code class="language-java"># logi
# LOG.info(&quot;&quot;);
# 适用于Java:表达式


# 模板内容
LOG.info(&quot;$END$&quot;);
</code></pre>

<h2 id="toc_3">logw</h2>

<pre class="line-numbers"><code class="language-java"># logw
# LOG.warn();
# 适用于Java:表达式

# 模板内容
LOG.warn($END$);
</code></pre>

<h2 id="toc_4">loge</h2>

<pre class="line-numbers"><code class="language-java"># loge
# LOG.error();
# 适用于Java:表达式

# 模板内容
LOG.error($END$);
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 哈希(Hash)  hscan Jedis正确使用方式]]></title>
    <link href="https://penghuicai.github.io/16577005420355.html"/>
    <updated>2022-07-13T16:22:22+08:00</updated>
    <id>https://penghuicai.github.io/16577005420355.html</id>
    <content type="html"><![CDATA[
<p><em>本文仅做为知识分享能力提升，分享不同业务需求场景应对的方式</em>。</p>

<p>Redis <code>HSCAN</code> 命令用于迭代哈希表中的键值对。</p>

<p><code>SCAN</code> 命令是一个基于游标的迭代器，每次被调用之后， 都会向用户返回一个新的游标， 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数， 以此来延续之前的迭代过程。</p>

<p><code>SCAN</code> 返回一个包含两个元素的数组， 第一个元素是用于进行下一次迭代的新游标， 而第二个元素则是一个数组， 这个数组中包含了所有被迭代的元素。如果新游标返回 0 表示迭代已结束。</p>

<h1 id="toc_0">语法</h1>

<pre class="line-numbers"><code class="language-text">HSCAN key cursor [MATCH pattern] [COUNT count]
</code></pre>

<ul>
<li>cursor - 游标</li>
<li>pattern - 匹配的模式[*]</li>
<li>count - 指定从数据集里返回多少元素，默认值为 10 </li>
</ul>

<h1 id="toc_1">语法示例</h1>

<pre class="line-numbers"><code class="language-text">redis 127.0.0.1:6379&gt; scan inv-key 0   # 使用 0 作为游标，开始新的迭代
1) &quot;17&quot; # 第一次迭代时返回的新游标
2)  1) &quot;key12&quot;
    2) &quot;value12&quot;
    3) &quot;key4&quot;
    4) &quot;value4&quot;
    5) &quot;key16&quot;
    6) &quot;value16&quot;
    7) &quot;key15&quot;
    8) &quot;value15&quot;
    9) &quot;key3&quot;
   10) &quot;value3&quot;
   11) &quot;key1&quot;
   12) &quot;value1&quot;
redis 127.0.0.1:6379&gt; scan inv-key 17   # 使用的是第一次迭代时返回的新游标 17 开始新的迭代
1) &quot;0&quot;
2) 1) &quot;key5&quot;
   2) &quot;value5&quot;
   3) &quot;key0&quot;
   4) &quot;value0&quot;
   5) &quot;key19&quot;
   6) &quot;value19&quot;
   7) &quot;key6&quot;
   8) &quot;value6&quot;
</code></pre>

<h1 id="toc_2">Java Jedis</h1>

<pre class="line-numbers"><code class="language-java">String stKey = &quot;xxx:xxx&quot;;
ScanParams scanParams = new ScanParams();
scanParams.count(10);
// 游标从0开始，以0结束
int cursor = 0;
while (true) {
    ScanResult&lt;Entry&lt;String, String&gt;&gt; scanResult = jedis.hscan(stKey, String.valueOf(cursor), scanParams);
    // 获取新游标
    cursor = Integer.parseInt(scanResult.getStringCursor());
    // 当前游标的数据集合
    List&lt;Entry&lt;String, String&gt;&gt; entryList = scanResult.getResult();
    // 获取到的数据集为空值时，大概率出现第一次迭代，没有任何数据集
    if (null == entryList || entryList.size() == 0) {
        break;
    }
    List&lt;String&gt; fields = new ArrayList&lt;&gt;();
    for (Entry&lt;String, String&gt; entry : entryList) {
        // todo
        // 业务处理
    }
    // 当下次游标为0的时候（游标从0开始，以0结束）
    // 表示数据集已全部读取完成，下一页将回到第一页
    if (cursor == 0) {
        break;
    }
}
jedis.del(stKey);
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL EXPLAIN 解读]]></title>
    <link href="https://penghuicai.github.io/16570104381381.html"/>
    <updated>2022-07-05T16:40:38+08:00</updated>
    <id>https://penghuicai.github.io/16570104381381.html</id>
    <content type="html"><![CDATA[
<p><code>EXPLAIN</code>作为<code>MySQL</code>的性能分析神器，可用来分析<code>SQL</code>的执行计划</p>

<h2 id="toc_0">EXPLAIN 示例</h2>

<pre class="line-numbers"><code class="language-text">EXPLAIN SELECT
    c.PK 
FROM
    consignments c
    JOIN pointofservice p ON p.PK = c.p_pointofservice
    JOIN orders o ON o.PK = c.p_order 
WHERE
    (
    c.p_consignmentdoctype IN ( 8796118450267, 8796118351963, 8796118384731 ) 
    AND c.p_status = 8796104753243 
    AND c.p_accountdocstatus = 8796093087835 
    AND (
    ( o.p_orderbstype = 8796854648923 AND p.p_bstype IN ( &#39;DS&#39;, &#39;JM&#39;, &#39;JR&#39; ) ) 
    OR ( o.p_orderbstype = 8796854616155 AND p.p_bstype IN ( &#39;MD&#39;, &#39;RD&#39;, &#39;DS&#39; ) ) 
    OR ( o.p_orderbstype = 8796854681691 AND p.p_bstype = &#39;DS&#39; ) 
    OR ( o.p_orderbstype = 8796854583387 AND p.p_bstype = &#39;JM&#39; ) 
    ) 
    ) 
    AND ( ( c.TypePkString = 8796107407442 AND p.TypePkString = 8796095250514 AND o.TypePkString = 8796094136402 ) ) 
    LIMIT 0,
    1000;
</code></pre>

<table>
<thead>
<tr>
<th>字段</th>
<th>含义</th>
</tr>
</thead>

<tbody>
<tr>
<td>id</td>
<td>该语句的唯一标识。如果<code>explain</code>的结果包括多个<code>id</code>值，则数字<code>越大越先执行</code>；而对于<code>相同id</code>的行，则表示<code>从上往下依次执行</code>。</td>
</tr>
<tr>
<td>select_type</td>
<td>查询类型</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[前端编译失败 `JavaScript heap out of memory`]]></title>
    <link href="https://penghuicai.github.io/16559527064386.html"/>
    <updated>2022-06-23T10:51:46+08:00</updated>
    <id>https://penghuicai.github.io/16559527064386.html</id>
    <content type="html"><![CDATA[
<pre class="line-numbers"><code class="language-text">FATAL ERROR：Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory
</code></pre>

<h1 id="toc_0">启动服务</h1>

<pre class="line-numbers"><code class="language-text">yarn install
# 启动roadhog
yarn build:dll
# 启动应用
yarn start
</code></pre>

<h1 id="toc_1">编译失败异常</h1>

<p><img src="media/16559527064386/16559527798736.jpg" alt=""/></p>

<h1 id="toc_2">原因可能是<code>nodejs</code>版本过低，升级版本后在尝试</h1>

<p><img src="media/16559527064386/16559528035670.jpg" alt=""/></p>

<h1 id="toc_3">查看<code>node</code>版本</h1>

<pre class="line-numbers"><code class="language-text">node -v
</code></pre>

<h1 id="toc_4">升级<code>node</code>版本</h1>

<h2 id="toc_5">mac系统</h2>

<p>以下命令在终端中可能会遇到权限问题，在开始位置输入<code>sudo</code>即可</p>

<ul>
<li>清除<code>npm</code>缓存，执行命令</li>
</ul>

<pre class="line-numbers"><code class="language-text">npm cache clean -f
</code></pre>

<ul>
<li><code>n模块</code>是专门用来管理<code>nodejs</code>的版本，安装<code>n模块</code></li>
</ul>

<pre class="line-numbers"><code class="language-text">npm install -g n
</code></pre>

<ul>
<li>更新升级<code>node</code>版本</li>
</ul>

<pre class="line-numbers"><code class="language-text">// 把当前系统的 Node 更新成最新的 “稳定版本”
 n stable
// 长期支持版
 n lts 
// 最新版
 n latest
// 指定安装版本
 n 10.14.2 
</code></pre>

<ul>
<li>删除指定<code>node</code>版本</li>
</ul>

<pre class="line-numbers"><code class="language-text">n rm 10.14.2
</code></pre>

<ul>
<li>查看升级后的<code>node</code>版本</li>
</ul>

<pre class="line-numbers"><code class="language-text">node -v
</code></pre>

<h2 id="toc_6">window系统</h2>

<ul>
<li><code>cmd</code>查看当前<code>node</code>版本和<code>node</code>安装位置</li>
</ul>

<pre class="line-numbers"><code class="language-text">node -v
where node
</code></pre>

<ul>
<li>百度搜索<code>node+需要版本</code>官网下载<code>LTS版本nodejs</code>。安装到之前的目录即可</li>
</ul>

<pre class="line-numbers"><code class="language-text">// node 下载地址 
https://nodejs.org/zh-cn/download/releases/
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 发布与订阅之查看订阅信息]]></title>
    <link href="https://penghuicai.github.io/16558847104015.html"/>
    <updated>2022-06-22T15:58:30+08:00</updated>
    <id>https://penghuicai.github.io/16558847104015.html</id>
    <content type="html"><![CDATA[
<p><em>本文仅做为知识分享能力提升，分享不同业务需求场景应对的方式</em>。</p>

<p><code>PUBSUB</code>命令是<code>Redis 2.8</code>新增加的命令之一，客户端可以通过这个命令来<code>查看频道</code>或者<code>模式</code>的相关信息<br/>
比如某个频道目前有多少订阅者，又或者某个模式目前有多少订阅者<br/>
消息之前保存消息：<code>SET cache:basestorerelwarehouse:r:8821127395054</code><br/>
查看消息内容：<code>GET  cache:basestorerelwarehouse:r:8821127395054</code></p>

<ul>
<li>
<a href="#toc_0">获取当前被订阅的频道</a>
</li>
<li>
<a href="#toc_1">获取指定频道的订阅者数量</a>
</li>
<li>
<a href="#toc_2">频道发布者(pub)发布消息</a>
</li>
<li>
<a href="#toc_3">频道订阅者(sub)订阅消息</a>
</li>
</ul>


<h1 id="toc_0">获取当前被订阅的频道</h1>

<ul>
<li>命令：</li>
</ul>

<pre class="line-numbers"><code class="language-text">PUBSUB CHANNELS [pattern]
</code></pre>

<ul>
<li>功能：活跃频道组成的列表，用于返回服务器当前被订阅的频道</li>
<li>参数<code>pattern</code>可选：
<ul>
<li>不给定<code>pattern</code>参数，命令返回当前被订阅的<code>所有频道</code></li>
<li>给定<code>pattern</code>参数，命令返回当前被订阅的频道中 与pattern模式<code>相匹配的频道</code></li>
</ul></li>
</ul>

<pre class="line-numbers"><code class="language-text">redis:0&gt;PUBSUB CHANNELS
 1)  &quot;notify:basestore:channel&quot;
 2)  &quot;notify:warehouse:channel&quot;
 3)  &quot;notify:city:channel&quot;
</code></pre>

<h1 id="toc_1">获取指定频道的订阅者数量</h1>

<ul>
<li>命令：</li>
</ul>

<pre class="line-numbers"><code class="language-text">PUBSUB NUMSUB [channel...]
</code></pre>

<ul>
<li>功能：返回指定频道的订阅者数量，返回接收到的信息</li>
<li>参数：<code>channel</code> 必填</li>
</ul>

<pre class="line-numbers"><code class="language-text">redis:0&gt;PUBSUB NUMSUB notify:basestore:channel notify:city:channel
 1)  &quot;notify:basestore:channel&quot;
 2)  &quot;4&quot;
 3)  &quot;notify:city:channel&quot;
 4)  &quot;2&quot;
</code></pre>

<h1 id="toc_2">频道发布者(pub)发布消息</h1>

<ul>
<li>命令：</li>
</ul>

<pre class="line-numbers"><code class="language-text">PUBLISH [channel] [message]
</code></pre>

<ul>
<li>功能：返回<code>接收到消息</code>的<code>订阅者数量</code></li>
<li>参数：<code>channel</code>与<code>message</code>必填</li>
<li>代码示例：</li>
</ul>

<pre class="line-numbers"><code class="language-text">PUBLISH notify:test:channel hello
</code></pre>

<h1 id="toc_3">频道订阅者(sub)订阅消息</h1>

<ul>
<li>命令：</li>
</ul>

<pre class="line-numbers"><code class="language-text">SUBSCRIBE channel [channel ...]
</code></pre>

<ul>
<li>功能：订阅指定的一个或多个频道的信息</li>
<li>参数：<code>channel</code>必填</li>
<li>代码示例：</li>
</ul>

<pre class="line-numbers"><code class="language-text">SUBSCRIBE notify:test:channel
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ZOC Terminal 8.01.5 序列号版 最好用的终端仿真器]]></title>
    <link href="https://penghuicai.github.io/16304764801806.html"/>
    <updated>2021-09-01T14:08:00+08:00</updated>
    <id>https://penghuicai.github.io/16304764801806.html</id>
    <content type="html"><![CDATA[
<p>版本：8.01.5</p>

<p>下载链接：<a href="https://url94.ctfile.com/f/11804594-511085294-5dbf31">ZOC_Terminal_8.01.5.dmg</a><br/>
访问密码：7051</p>

<pre class="line-numbers"><code class="language-text"># the first sn-part:
51698/01027/34713

and the second sn part being:
00937
</code></pre>

<blockquote>
<p>资源来源 <a href="https://xclient.info/s/zoc-terminal.html#versions">Xclient</a></p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[cisco AnyConnect Secure Mobility Client v4.8 for Mac 思科]]></title>
    <link href="https://penghuicai.github.io/16304749732861.html"/>
    <updated>2021-09-01T13:42:53+08:00</updated>
    <id>https://penghuicai.github.io/16304749732861.html</id>
    <content type="html"><![CDATA[
<p>版本：4.8.00175</p>

<p>下载链接： <a href="https://url94.ctfile.com/f/11804594-511079987-1e70c0">anyconnect-macos-4.8.00175-predeploy-k9.dmg</a><br/>
访问密码：7051</p>

<blockquote>
<p>资料来源 <a href="https://software.cisco.com/download/home/286281283/type">https://software.cisco.com/</a></p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mac 工具网站记录]]></title>
    <link href="https://penghuicai.github.io/16304746256161.html"/>
    <updated>2021-09-01T13:37:05+08:00</updated>
    <id>https://penghuicai.github.io/16304746256161.html</id>
    <content type="html"><![CDATA[
<ol>
<li><a href="https://xclient.info/s/">Xclient</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[删库跑路？如果能够快速删除一张亿级表？]]></title>
    <link href="https://penghuicai.github.io/16298733466823.html"/>
    <updated>2021-08-25T14:35:46+08:00</updated>
    <id>https://penghuicai.github.io/16298733466823.html</id>
    <content type="html"><![CDATA[
<p><em>本文仅做为知识分享能力提升，分享不同业务需求场景应对的方式</em>。<br/>
<strong>恶意删库跑路属于删除计算机信息系统中存储的数据，如造成特别严重的后果，行为会构成破坏计算机信息系统罪。</strong></p>

<ul>
<li>
<a href="#toc_0">一、DELETE TABLE</a>
<ul>
<li>
<a href="#toc_1">DELETE 说明</a>
</li>
<li>
<a href="#toc_2">DELETE 示例</a>
</li>
</ul>
</li>
<li>
<a href="#toc_3">二、TRUNCATE TABLE</a>
<ul>
<li>
<a href="#toc_4">TRUNCATE 说明</a>
</li>
<li>
<a href="#toc_5">TRUNCATE 示例</a>
</li>
</ul>
</li>
<li>
<a href="#toc_6">三、DROP TABLE</a>
<ul>
<li>
<a href="#toc_7">DROP 说明</a>
</li>
<li>
<a href="#toc_8">DROP 示例</a>
</li>
</ul>
</li>
<li>
<a href="#toc_9">四、扩展点</a>
<ul>
<li>
<a href="#toc_10">OPTIMIZE TABLE 命令优化表</a>
</li>
</ul>
</li>
</ul>


<h1 id="toc_0">一、DELETE TABLE</h1>

<h2 id="toc_1">DELETE 说明</h2>

<ul>
<li><strong>删除速度慢：</strong>操作会被放在 rollback segment 中，事物提交后才生效，如果有相应的 trigger 执行将被触发，如果删除大数据量的表速度会很慢；</li>
<li><strong>可 rollback 操作：</strong>为 <code>DML</code> 数据操作语言，对数据库中记录做删除标记，每次从表中删除一行，并且同时讲该行的删除操作作为事物记录在日志中保存可以进行 rollback 操作；</li>
<li><strong>不直接释放磁盘空间：</strong>删除表中的逻辑数据，但是物理数据不清除，如主键值、索引等不被清除；虽然未释放磁盘空间，但是下次插入数据的时候，仍然可以重用这部分空间(重用 -&gt; 覆盖)。也可以使用OPTIMIZE TABLE 对碎片进行整理可降低空间占用；</li>
<li><strong>约束影响范围：</strong>删除范围可以添加 <code>WHERE</code> 约束影响范围。 </li>
</ul>

<h2 id="toc_2">DELETE 示例</h2>

<p>删除整张表的数据：</p>

<pre class="line-numbers"><code class="language-mysql">DELETE FROM table_name;
</code></pre>

<p>删除部分数据，添加 where 子句：</p>

<pre class="line-numbers"><code class="language-mysql">DELETE FROM table_name WHERE ... ;
</code></pre>

<p>分批删除数据，避免长事务，减少其他客户端资源等待的时间：</p>

<pre class="line-numbers"><code class="language-mysql">DELETE FROM table_name ORDER BY index_field LIMIT 1000；
</code></pre>

<h1 id="toc_3">二、TRUNCATE TABLE</h1>

<h2 id="toc_4">TRUNCATE 说明</h2>

<ul>
<li><strong>速度快：</strong>通过释放数据表数据所用的数据页，来删除数据，并且只在事务日志中记录页的释放，使用系统和事物日志资源少；</li>
<li><strong>不能 rollback 操作：</strong>为 <code>DDL</code>  数据库模式定义语言，删除数据表所有行，操作立即生效，原数据不放到 rollback segment 中不可进行 rollback 操作。FOREIGN KEY 约束引用的表，不能使它，它不记录在日志所以 trigger 不能被激活；</li>
<li><strong>立刻释放磁盘空间：</strong>同时针对具有自动递增值的字段，做计数重置归零重新计算；</li>
<li><strong>无法控制影响范围：</strong>删除数据表内所有行，但表结构及其列、约束、索引结构等保持不变。</li>
</ul>

<h2 id="toc_5">TRUNCATE 示例</h2>

<p>删除整张表的数据：</p>

<pre class="line-numbers"><code class="language-mysql">TRUNCATE TABLE table_name
</code></pre>

<h1 id="toc_6">三、DROP TABLE</h1>

<h2 id="toc_7">DROP 说明</h2>

<ul>
<li><strong>速度快</strong></li>
<li><strong>不能 rollback 操作：</strong> 为 <code>DDL</code>  数据库模式定义语言，表数据和结构都会被删除；</li>
<li><strong>立刻释放磁盘空间：</strong>删除表定义及该表的所有数据、索引、触发器、约束和权限规范；</li>
<li><strong>无法控制影响范围：</strong>删除数据表内所有行。</li>
</ul>

<h2 id="toc_8">DROP 示例</h2>

<pre class="line-numbers"><code class="language-mysql">DROP TABLE table_name;
</code></pre>

<h1 id="toc_9">四、扩展点</h1>

<h2 id="toc_10">OPTIMIZE TABLE 命令优化表</h2>

<ul>
<li>该命令会重新利用未使用的空间，并整理数据文件的碎片</li>
<li>该命令将会整理表数据和相关的索引数据的物理存储空间，用来减少占用的磁盘空间，并提高访问表时候的IO性能；</li>
<li>不可以频繁操作，释放磁盘空间，优化表期间会锁定表，所以要在空闲时段执行。</li>
<li><code>OPTIMIZE TABLE table_name；</code></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP HTTPS SSL TLS 相关知识]]></title>
    <link href="https://penghuicai.github.io/16297846641794.html"/>
    <updated>2021-08-24T13:57:44+08:00</updated>
    <id>https://penghuicai.github.io/16297846641794.html</id>
    <content type="html"><![CDATA[
<ul>
<li>
<a href="#toc_0">HTTP 相关</a>
<ul>
<li>
<a href="#toc_1">一、HTTP 是什么？</a>
</li>
<li>
<a href="#toc_2">二、HTTP 请求有哪些方法？</a>
</li>
<li>
<a href="#toc_3">三、GET、POST 请求有哪些区别？</a>
</li>
<li>
<a href="#toc_4">四、 GET 请求有 Request body？参数可以像 POST 请求一样放在这里吗？</a>
</li>
</ul>
</li>
</ul>


<h2 id="toc_0">HTTP 相关</h2>

<h3 id="toc_1">一、HTTP 是什么？</h3>

<ul>
<li>HTTP 协议是 Hyper Text Transfer Protocol（超文本传输协议）的缩写，是用于万维网（WWW : World Wide Web、3W、Web）服务器传输超文本到本地浏览器的传输协议。</li>
<li>HTTP 是一个基于 TCP/IP 通信协议来传递数据（HTML文件，图片文件，查询结构等）</li>
<li>HTTP 是一个数据应用层的面向对象协议，由于简洁快速的方式，适用于分布式超媒体信息系统。它与1990年提出，经历几年的使用与发展，得到了不断地完善和扩展。</li>
<li>HTTP协议工作与客户端和服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端（WEB服务端）发送所有请求。Web服务器根据收到的请求，向客户端发送响应信息</li>
</ul>

<h3 id="toc_2">二、HTTP 请求有哪些方法？</h3>

<p>在 <code>HTTP/1.1</code> 共定义了 <code>八种</code> 请求方法（也叫动作）来表明 Request-URL 指定的资源有不同的操作方式</p>

<ul>
<li>HTTP/0.9 定义 <code>一种</code> 请求方法：GET</li>
<li>HTTP/1.0 新增加 <code>两种</code> 请求方法 ：POST 和 HEAD 方法</li>
<li>HTTP/1.1 中，新增加 <code>五种</code> 请求方法：OPTIONS、PUT、DELETE、TRACE 和 CONNECT。</li>
<li>我们一般常用的就是：GET、POST</li>
<li>补充：</li>
</ul>

<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>GET</td>
<td>向特定的资源发出请求，并返回实体主体</td>
</tr>
<tr>
<td>HEAD</td>
<td>类似于GET，返回的响应实体没有具体的内容，用于获取响应消息头中的元数据</td>
</tr>
<tr>
<td>POST</td>
<td>向指定资源提交数据进行处理请求（列如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。</td>
</tr>
<tr>
<td>PUT</td>
<td>向指定资源位置上传其最新内容</td>
</tr>
<tr>
<td>OPTIONS</td>
<td>返回服务器针对特定资源所支持的HTTP请求方法，也可以利用向web服务器发送‘*’的请求来测试服务的功能性</td>
</tr>
<tr>
<td>DELETE</td>
<td>请求服务器删除Request-URL所标识的资源</td>
</tr>
<tr>
<td>TRACE</td>
<td>回显服务器收到的请求，主要用于测试或诊断</td>
</tr>
<tr>
<td>CONNECT</td>
<td>HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。</td>
</tr>
</tbody>
</table>

<h3 id="toc_3">三、GET、POST 请求有哪些区别？</h3>

<ol>
<li>GET 请求在 URL 中传递的参数是有长度限制的，而 POST 没有；</li>
<li>GET 比 POST 更不安全，因为参数直接暴露在URL中，不能传递敏感信息。而 POST 数据不会显示在 URL 中。是放在Request body中；</li>
<li>对参数的数据类型，GET 只接受 ASCII 字符，而POST没有限制；</li>
<li>GET 请求参数会被完整保留在浏览器历史记录里。POST 请求参数不会被浏览器保留；</li>
<li>GET 请求只能进行URL编码（application/x-www-from-urlencoded），而 POST 支持多种编码格式；</li>
<li>GET 请求会被浏览器主动缓存，而 POST 不会，除非手动设置；</li>
<li>GET 在浏览器回退是无害的，而 POST 会再次提交请求。</li>
</ol>

<h3 id="toc_4">四、 GET 请求有 Request body？参数可以像 POST 请求一样放在这里吗？</h3>

<p>其实，前面我们说到 HTTP 是一个基于 TCP/IP，GET 和 POST 在本质上没有区别，都是 HTTP 发送请求的两种请求方法。所以 GET 和 POST 的底层也是TCP/IP。也就是说，GET 和 POST 都是 TCP 连接。所以 GET 加 Request body 或者 POST 的 URL 带上参数，从技术上是完全行的通的。<br/>
TCP 就像汽车，我们用 TCP 运输数据很可靠，从来不会发生丢件少件的现象。<br/>
但是如果路上跑的全是看起来一模一样的汽车，那这个世界看起来是一团混乱，送急件的汽车可能就被前面载满货物的汽车堵在路上，真个交通系统一定会瘫痪。<br/>
为了避免这种情况发生，交通规则HTTP诞生了，HTTP给汽车运输设定了几个服务类别，包括 GET、POST、PUT 等等。<br/>
HTTP 规定，当执行 GET 请求的时候，要给车贴上 GET 标签，要求其数据货物放在车顶（URL中）以方便记录。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL 索引使用情况统计 information_schema.INDEX_STATISTICS]]></title>
    <link href="https://penghuicai.github.io/16140620588310.html"/>
    <updated>2021-02-23T14:34:18+08:00</updated>
    <id>https://penghuicai.github.io/16140620588310.html</id>
    <content type="html"><![CDATA[
<p>MySQL的开源版本 MariaDB、Percona MySQL Server 和 AliSQL 5.6 版本支持统计索引的信息，即可以统计出使用某个索引扫描的行数。依照此，可以找出未被使用的，或者使用频率较低的索引，从而进行下线。</p>

<h2 id="toc_0">示例</h2>

<pre class="line-numbers"><code class="language-text">mysql&gt; select * from wstest.test2 where name=&#39;aaax&#39;;  
+----+------+--------+------+-------+  
| id | name | status | addr | addr2 |  
+----+------+--------+------+-------+  
|  5 | aaax |      5 |      |     0 |  
+----+------+--------+------+-------+  
1 row in set (0.00 sec)  
</code></pre>

<h2 id="toc_1">查看统计信息</h2>

<p>注意：最开始查询 information_schema.INDEX_STATISTICS 表发现结果为空时需要打开参数才会进行统计。<br/>
打开参数：<code>loose_rds_indexstat=1</code></p>

<pre class="line-numbers"><code class="language-text">mysql&gt; select * from information_schema.INDEX_STATISTICS where table_schema=&#39;wstest&#39; and table_name=&#39;test2&#39;;  
+--------------+------------+------------+-----------+  
| TABLE_SCHEMA | TABLE_NAME | INDEX_NAME | ROWS_READ |  
+--------------+------------+------------+-----------+  
| wstest       | test2      | idx_name   |         1 |  
| wstest       | test2      | PRIMARY    |   6314081 |  
+--------------+------------+------------+-----------+  
2 rows in set (0.02 sec)  
</code></pre>

<h2 id="toc_2">统计介绍</h2>

<p>由于在使用 idx_name查 询数据时，扫描行数为1所以在 information_schema.INDEX_STATISTICS 表的 ROWS_READ 字段对应的值为 1 ；<br/>
若再次使用 idx_name 查询，则 ROWS_READ 会再次加 1 。</p>

<h2 id="toc_3">索引下线</h2>

<h3 id="toc_4">设置索引不可见</h3>

<p>使索引不可见，避免突然下线导致某些应用出现慢查。</p>

<pre class="line-numbers"><code class="language-text">mysql&gt; alter table test2 alter index idx_name invisible;
</code></pre>

<h3 id="toc_5">删除索引</h3>

<p>设置索引不可见之后，可以过一段时间，选择低峰期将索引进行删除：</p>

<pre class="line-numbers"><code class="language-text">mysql &gt; alter table test2 drop index idx_name;
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vuejs 脚手架 vue-cli 开始 Vuejs 项目]]></title>
    <link href="https://penghuicai.github.io/16068990354499.html"/>
    <updated>2020-12-02T16:50:35+08:00</updated>
    <id>https://penghuicai.github.io/16068990354499.html</id>
    <content type="html"><![CDATA[
<pre class="line-numbers"><code class="language-shell">$ sudo npm install -g vue-cli

❯ Yes, use Yarn  

$ vue list 

$ vue init webpack wlt-demo
# ? Project name wlt-demo
# ? Project description A Vue.js project
# ? Author kellen_cai@126.com
# ? Vue build standalone
# ? Install vue-router? Yes
# ? Use ESLint to lint your code? Yes
# ? Pick an ESLint preset Standard
# ? Set up unit tests No
# ? Setup e2e tests with Nightwatch? No
# ? Should we run `npm install` for you after the # project has been created? (recommended) yarn 

$ cd wlt-demo
# $ npm run dev
$ yarn run dev
# http://localhost:8080
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mac 允许任何来源 App 运行]]></title>
    <link href="https://penghuicai.github.io/16052597148068.html"/>
    <updated>2020-11-13T17:28:34+08:00</updated>
    <id>https://penghuicai.github.io/16052597148068.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">打开终端应用 执行下方命令，并按提示输入密码即可显示</h2>

<pre class="line-numbers"><code class="language-text"> sudo spctl --master-disable
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HTTP POST 请求被浏览器强制转换为 GET 请求]]></title>
    <link href="https://penghuicai.github.io/16045635590464.html"/>
    <updated>2020-11-05T16:05:59+08:00</updated>
    <id>https://penghuicai.github.io/16045635590464.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">遇到这种情况，检查一下访问的 URL 是 HTTP 还是 HTTPS</h2>

<h2 id="toc_1">原因 Nginx 做 HTTP 重定向到 HTTPS ，POST 才变成 GET 请求</h2>

<ol>
<li>浏览器客户端发送 POST 请求，Nginx 返回 302 暂时性转移到 HTTPS</li>
<li>浏览器客户端收到 302 后，通过 HTTPS 向服务器发起新的请求</li>
<li>新的请求就变成了 GET 请求</li>
</ol>

<h2 id="toc_2">说明</h2>

<p>因为做了Nginx HTTP 重定向到 HTTPS，他们这种访问 API 的方式才出错的。<br/>
大多数 HTTP 浏览器客户端会将引起 302 的 POST 请求转化为 GET 请求发出去。<br/>
其实这是将 302 当做 303 来处理，至于为什么会将 302 当做 303 来处理，据说这是很多老服务器的期望行为，所以一切都是为了兼容性。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ImpEx 多表单行导出]]></title>
    <link href="https://penghuicai.github.io/16045412531522.html"/>
    <updated>2020-11-05T09:54:13+08:00</updated>
    <id>https://penghuicai.github.io/16045412531522.html</id>
    <content type="html"><![CDATA[
<pre class="line-numbers"><code class="language-text">&quot;$query=select {pk} from {Consignment} where {code}=&#39;XS20062200002001&#39;&quot;
&quot;#% impex.setTargetFile(&quot;&quot;consignment.txt&quot;&quot;);&quot;
INSERT_UPDATE Consignment;code;consignmentExtend(orderApproveTimes)[alias=&#39;ConsignmentExtend.orderApproveTimes&#39;];consignmentExtend(isNoticeNewPosStatus(code))[alias=&#39;通知新POS状态&#39;];
&quot;#% impex.exportItemsFlexibleSearch(&quot;&quot;$query&quot;&quot;, Collections.EMPTY_MAP, Collections.singletonList( Item.class ), true, true, -1, -1);&quot;

##### ndcWarehouses是一个set集合，无多对多关联关系表，仅保留pk表的PK，导出对应字段model的任意字段，包括它关联model的字段
&quot;$query=select {pk} FROM {UserGroup} WHERE {uid} = &#39;admingroup&#39;&quot;
&quot;#% impex.setTargetFile(&quot;&quot;UserGroup.txt&quot;&quot;);&quot;
INSERT_UPDATE UserGroup;uid;ndcWarehouses(code);
&quot;#% impex.exportItemsFlexibleSearch(&quot;&quot;$query&quot;&quot;, Collections.EMPTY_MAP, Collections.singletonList( Item.class ), true, true, -1, -1);&quot;
</code></pre>

<p>ImpEx 导出 省市区</p>

<pre class="line-numbers"><code class="language-text">&quot;$query=select {pk} from {District}&quot;
&quot;#% impex.setTargetFile(&quot;&quot;District.txt&quot;&quot;);&quot;
INSERT_UPDATE District;code[alias=&#39;区县&#39;];name[lang=zh,alias=&#39;区县&#39;];city(code);city(name[lang=zh])[alias=&#39;市&#39;];city(region(isocode))[alias=&#39;省&#39;];city(region(name[lang=zh]))[alias=&#39;省&#39;];city(region(country(isocode)))[alias=&#39;国家&#39;];city(region(country(name[lang=zh])))[alias=&#39;国家&#39;];
&quot;#% impex.exportItemsFlexibleSearch(&quot;&quot;$query&quot;&quot;, Collections.EMPTY_MAP, Collections.singletonList( Item.class ), true, true, -1, -1);&quot;
</code></pre>

<p>导出</p>

<pre class="line-numbers"><code class="language-text">&quot;$query=select {c.pk} from {consignment as c} where {c.modifiedtime} &lt; &#39;2021-04-07 09:40:00&#39; AND {c.acceptedStatus} = 8796118745179 &quot;
&quot;#% impex.setTargetFile(&quot;&quot;consignment.txt&quot;&quot;);&quot;
INSERT_UPDATE Consignment;code;status(name[lang=zh])[alias=&#39;状态&#39;];occupyStatus(name[lang=zh])[alias=&#39;占货状态&#39;];acceptedStatus(name[lang=zh])[alias=&#39;接受状态&#39;];abnormalType(name[lang=zh])[alias=&#39;异常类型&#39;];abnormalStatus(name[lang=zh])[alias=&#39;异常状态&#39;];
&quot;#% impex.exportItemsFlexibleSearch(&quot;&quot;$query&quot;&quot;, Collections.EMPTY_MAP, Collections.singletonList( Item.class ), true, true, -1, -1);&quot;
</code></pre>

<h1 id="toc_0">ImpEx 多表单行导入</h1>

<pre class="line-numbers"><code class="language-text">INSERT_UPDATE Consignment;code[unique=true];approvedTimes;consignmentExtend(orderApproveTimes);consignmentExtend(isNoticeNewPosStatus(code));
;XS20062200002001;1;2;PENDING


INSERT_UPDATE Consignment;code[unique=true];approvedTimes;consignmentExtend(orderApproveTimes);
;XS20062200002001;1;2;
</code></pre>

]]></content>
  </entry>
  
</feed>
